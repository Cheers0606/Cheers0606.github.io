[{"title":"Spark动态加载hive配置的方案","url":"/2021/07/14/Spark动态加载hive配置的方案/","content":"> 转载自 (莱哥博客)[https://leibnizhu.github.io/2020/05/06/%E5%8A%A8%E6%80%81%E5%8A%A0%E8%BD%BDhive%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E7%9A%84%E6%96%B9%E6%A1%88/]\n\n一般来说，Spark写Hive，把 <font color=gray>xxx-site.xml</font>系列配置文件打进jar包里，或spark-submit指定下file之类，new个HiveContext就完事了。\n要写外部集群，也不外乎是换对应的<font color=gray>xxx-site.xml</font>，改改<font color=gray>thrift</font>服务地址啥的，不费劲。\n好了，本文结束。\n\n不对，擅长断更的我不会为此特意写篇博客。\n\n现在的场景是，每次Spark任务启动的时候才能拿到外部Hive集群的配置信息（别问我为什么，问就是中台的需求，很多集群，java应用启动后才能去读到任务配置，反射组装RDD并执行，Hive配置？lazy的，到写入的时候才会去拿）。\n\n这个过程踩了不少坑，试了几种方案，直接说结论吧。\n\n+ SparkContext创建的时候会创建一个Configuration对象（注意 loadDefaults=true)，写入Hive会用到它；而这个Configuration对象里面已经放了常规的那些***-site.xml系列配置文件作为 defaultResources，这时写入Hive相当于按fat-jar里面的配置来了；\n+ 围观Configuration代码，reload配置之后会将defaultResources逐个读出，而defaultResources是个有序的List，那么显然可以用Configuration#addDefaultResource()把外部集群的相关配置xml设置为默认资源，这样拿配置的时候就会拿到外部集群的配置啦！！！\n+ 为了方便配置的读取，直接放在hdfs吧，这样直接Configuration.addDefaultResource(\"hdfs:///path/to/hive-site.xml\")不就可以了吗？诶怎么不行，再围观Configuration代码，可以看到加载默认资源最终用的是Configuration#getResource()方法，这个方法体就一句话：return classLoader.getResource(name);，也就是说，它不会去解析hdfs协议，而是直接从classpath里面去读取。所以不能直接从hdfs读取；\n+ 最后的方案是把配置文件放在hdfs，写入Hive前，把它下载到当前classpath的其中某个目录下（比如classpath包含. 则下载到System.getProperty(\"user.dir\")下），然后Configuration.addDefaultResource(\"hive-site.xml\")，因为Configuration是用ClassLoader进行加载的，所以注意路径没有/。\n+ 这就完事了？并不，跑起来会发现还是查询jar包里的hive metastore地址，所以还要解析hive-site.xml，读取出hive.metastore.uris值并放入环境变量中。\n+ 这就完事了？并不，考虑到后续还会有其他写入操作，以及SparkContext.stop()操作，这些操作都会用到Configuration读取配置，然而现在以及有了外部集群的默认资源了，需要删掉，然而Configuration并没有提供删除默认资源的方法，所以这里要手动反射删除之。","tags":["spark"],"categories":["spark"]},{"title":"Elasticsearch-源码编译运行","url":"/2021/02/08/Elasticsearch-源码编译运行/","tags":["default"],"categories":["default"]},{"title":"标签体系改造-TEST","url":"/2021/01/19/标签体系改造-TEST/","content":"# 测试\n## 创建es mapping\n```bash\nPUT /trident_test_497\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"vertical\": {\n          \"type\": \"pattern\",\n          \"parttern\": \"\\\\|\"\n        }\n      }\n    }\n  },\n  \"mappings\": {\n    \"label_default\": {\n      \"_all\": {\n        \"enabled\": false\n      },\n      \"_parent\": {\n        \"type\": \"info\"\n      },\n      \"_routing\": {\n        \"required\": true\n      },\n      \"dynamic_templates\": [\n        {\n          \"time\": {\n            \"match\": \"*_time\",\n            \"match_mapping_type\": \"string\",\n            \"mapping\": {\n              \"format\": \"strict_date_optional_time||yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis\",\n              \"type\": \"date\"\n            }\n          }\n        },\n        {\n          \"timestamp\": {\n            \"match\": \"*_time\",\n            \"match_mapping_type\": \"long\",\n            \"mapping\": {\n              \"format\": \"strict_date_optional_time||epoch_millis\",\n              \"type\": \"date\"\n            }\n          }\n        },\n        {\n          \"default\": {\n            \"match\": \"*\",\n            \"match_mapping_type\": \"string\",\n            \"mapping\": {\n              \"type\": \"keyword\"\n            }\n          }\n        }\n      ]\n    },\n    \"label_basic\": {\n      \"_all\": {\n        \"enabled\": false\n      },\n      \"_parent\": {\n        \"type\": \"info\"\n      },\n      \"_routing\": {\n        \"required\": true\n      },\n      \"dynamic_templates\": [\n        {\n          \"time\": {\n            \"match\": \"*_time\",\n            \"match_mapping_type\": \"string\",\n            \"mapping\": {\n              \"format\": \"strict_date_optional_time||yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis\",\n              \"type\": \"date\"\n            }\n          }\n        },\n        {\n          \"timestamp\": {\n            \"match\": \"*_time\",\n            \"match_mapping_type\": \"long\",\n            \"mapping\": {\n              \"format\": \"strict_date_optional_time||epoch_millis\",\n              \"type\": \"date\"\n            }\n          }\n        },\n        {\n          \"default\": {\n            \"match\": \"*\",\n            \"match_mapping_type\": \"string\",\n            \"mapping\": {\n              \"type\": \"keyword\"\n            }\n          }\n        }\n      ]\n    },\n    \"info\": {\n      \"_all\": {\n        \"enabled\": false\n      },\n      \"dynamic_templates\": [\n        {\n          \"time\": {\n            \"match\": \"*_time\",\n            \"match_mapping_type\": \"string\",\n            \"mapping\": {\n              \"format\": \"strict_date_optional_time||yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis\",\n              \"type\": \"date\"\n            }\n          }\n        },\n        {\n          \"timestamp\": {\n            \"match\": \"*_time\",\n            \"match_mapping_type\": \"long\",\n            \"mapping\": {\n              \"format\": \"strict_date_optional_time||epoch_millis\",\n              \"type\": \"date\"\n            }\n          }\n        },\n        {\n          \"default\": {\n            \"match\": \"*\",\n            \"match_mapping_type\": \"string\",\n            \"mapping\": {\n              \"type\": \"keyword\"\n            }\n          }\n        }\n      ],\n      \"properties\": {\n        \"activate_days\": {\n          \"type\": \"integer\"\n        },\n        \"age\": {\n          \"type\": \"integer\"\n        },\n        \"birthday\": {\n          \"type\": \"date\"\n        },\n        \"children_size\": {\n          \"type\": \"integer\"\n        },\n        \"city\": {\n          \"type\": \"keyword\"\n        },\n        \"city_level\": {\n          \"type\": \"keyword\"\n        },\n        \"community\": {\n          \"type\": \"keyword\"\n        },\n        \"constellation\": {\n          \"type\": \"keyword\"\n        },\n        \"contact_address\": {\n          \"type\": \"keyword\"\n        },\n        \"contact_email\": {\n          \"type\": \"keyword\"\n        },\n        \"contact_phone\": {\n          \"type\": \"keyword\"\n        },\n        \"contact_telephone\": {\n          \"type\": \"keyword\"\n        },\n        \"created_time\": {\n          \"type\": \"date\"\n        },\n        \"district\": {\n          \"type\": \"keyword\"\n        },\n        \"downgrade_cnt\": {\n          \"type\": \"integer\"\n        },\n        \"education\": {\n          \"type\": \"keyword\"\n        },\n        \"family_annual_income\": {\n          \"type\": \"integer\"\n        },\n        \"family_size\": {\n          \"type\": \"integer\"\n        },\n        \"gender\": {\n          \"type\": \"integer\"\n        },\n        \"group_id\": {\n          \"type\": \"keyword\"\n        },\n        \"industry\": {\n          \"type\": \"keyword\"\n        },\n        \"internet_habits\": {\n          \"type\": \"keyword\"\n        },\n        \"is_activate\": {\n          \"type\": \"integer\"\n        },\n        \"is_downgrade\": {\n          \"type\": \"integer\"\n        },\n        \"is_employee\": {\n          \"type\": \"integer\"\n        },\n        \"is_first_complete_personal_data\": {\n          \"type\": \"keyword\"\n        },\n        \"is_have_children\": {\n          \"type\": \"integer\"\n        },\n        \"is_have_pet\": {\n          \"type\": \"integer\"\n        },\n        \"is_member\": {\n          \"type\": \"integer\"\n        },\n        \"kol_points\": {\n          \"type\": \"integer\"\n        },\n        \"life_cycle\": {\n          \"type\": \"keyword\"\n        },\n        \"loyalty\": {\n          \"type\": \"integer\"\n        },\n        \"marital_status\": {\n          \"type\": \"keyword\"\n        },\n        \"market_area\": {\n          \"type\": \"keyword\"\n        },\n        \"member_duration\": {\n          \"type\": \"integer\"\n        },\n        \"member_level\": {\n          \"type\": \"keyword\"\n        },\n        \"member_source\": {\n          \"type\": \"keyword\"\n        },\n        \"member_status\": {\n          \"type\": \"keyword\"\n        },\n        \"open_ids\": {\n          \"type\": \"keyword\"\n        },\n        \"p_date\": {\n          \"type\": \"keyword\"\n        },\n        \"personal_annual_income\": {\n          \"type\": \"integer\"\n        },\n        \"points_balance\": {\n          \"type\": \"integer\"\n        },\n        \"points_to_expired\": {\n          \"type\": \"integer\"\n        },\n        \"prev_level_change_time\": {\n          \"type\": \"date\"\n        },\n        \"previous_life_cycle\": {\n          \"type\": \"keyword\"\n        },\n        \"previous_member_level\": {\n          \"type\": \"keyword\"\n        },\n        \"profession\": {\n          \"type\": \"keyword\"\n        },\n        \"province\": {\n          \"type\": \"keyword\"\n        },\n        \"receive_address\": {\n          \"type\": \"keyword\"\n        },\n        \"resident_address\": {\n          \"type\": \"keyword\"\n        },\n        \"rfm\": {\n          \"type\": \"keyword\"\n        },\n        \"tb_phone\": {\n          \"type\": \"keyword\"\n        },\n        \"tenant_code\": {\n          \"type\": \"keyword\"\n        },\n        \"update_time\": {\n          \"type\": \"date\"\n        },\n        \"user_id\": {\n          \"type\": \"keyword\"\n        },\n        \"user_name\": {\n          \"type\": \"keyword\"\n        },\n        \"user_source\": {\n          \"type\": \"keyword\"\n        },\n        \"work_address\": {\n          \"type\": \"keyword\"\n        },\n        \"wx_phone\": {\n          \"type\": \"keyword\"\n        },\n        \"wx_union_id\": {\n          \"type\": \"keyword\"\n        }\n      }\n    },\n    \"doc\": {\n      \"_all\": {\n        \"enabled\": false\n      },\n      \"dynamic_templates\": [\n        {\n          \"time\": {\n            \"match\": \"*_time\",\n            \"match_mapping_type\": \"string\",\n            \"mapping\": {\n              \"format\": \"strict_date_optional_time||yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis\",\n              \"type\": \"date\"\n            }\n          }\n        },\n        {\n          \"timestamp\": {\n            \"match\": \"*_time\",\n            \"match_mapping_type\": \"long\",\n            \"mapping\": {\n              \"format\": \"strict_date_optional_time||epoch_millis\",\n              \"type\": \"date\"\n            }\n          }\n        },\n        {\n          \"default\": {\n            \"match\": \"*\",\n            \"match_mapping_type\": \"string\",\n            \"mapping\": {\n              \"type\": \"keyword\"\n            }\n          }\n        }\n      ],\n      \"properties\": {\n        \"id\": {\n          \"type\": \"keyword\"\n        },\n        \"label_1970\": {\n          \"type\": \"keyword\"\n        },\n        \"label_1970_expire_time\": {\n          \"type\": \"date\"\n        },\n        \"label_1970_update_time\": {\n          \"type\": \"date\"\n        },\n        \"parent_id\": {\n          \"type\": \"keyword\"\n        }\n      }\n    },\n    \"_default_\": {\n      \"_all\": {\n        \"enabled\": false\n      },\n      \"dynamic_templates\": [\n        {\n          \"time\": {\n            \"match\": \"*_time\",\n            \"match_mapping_type\": \"string\",\n            \"mapping\": {\n              \"format\": \"strict_date_optional_time||yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis\",\n              \"type\": \"date\"\n            }\n          }\n        },\n        {\n          \"timestamp\": {\n            \"match\": \"*_time\",\n            \"match_mapping_type\": \"long\",\n            \"mapping\": {\n              \"format\": \"strict_date_optional_time||epoch_millis\",\n              \"type\": \"date\"\n            }\n          }\n        },\n        {\n          \"default\": {\n            \"match\": \"*\",\n            \"match_mapping_type\": \"string\",\n            \"mapping\": {\n              \"type\": \"keyword\"\n            }\n          }\n        }\n      ]\n    }\n  }\n}\n```\n## 添加一个标签树\n```bash\nPUT /trident_test_497/label_default/_mapping\n\n{\n  \"properties\": {\n    \"tree_1_label\": {\n      \"type\": \"string\"\n    },\n    \"tree_1_label_expire_time\": {\n      \"type\": \"string\"\n    },\n    \"tree_1_label_update_time\": {\n      \"type\": \"string\"\n    }\n  }\n}\n```\n## 刷数据进es\n```sql\nCREATE EXTERNAL TABLE db_datastory_trident.tmp_trident_es_543_1_label_3275(user_id string,tree_1_label string,tree_1_label_update_time string,tree_1_label_expire_time string) \nSTORED BY 'org.elasticsearch.hadoop.hive.EsStorageHandler' \nTBLPROPERTIES(\n\"es.nodes\"=\"dev1:9203,dev1:9204\",\n\"es.write.operation\"=\"upsert\",\n\"es.update.retry.on.conflict\"=\"10\",\n\"es.resource\"=\"trident_test_497/label_default\",\n\"es.mapping.id\"=\"user_id\",\n\"es.mapping.parent\"=\"user_id\",\n\"es.mapping.routing\"=\"user_id\",\n\"es.mapping.names\"=\"user_id:user_id,tree_1_label:tree_1_label,tree_1_label_update_time:tree_1_label_update_time,tree_1_label_expire_time:tree_1_label_expire_time\"\n);\n\n\nINSERT INTO TABLE db_datastory_trident.tmp_trident_es_543_1_label_3275\nSELECT entity_id,\n       CONCAT_WS('|' ,collect_set(concat(label_id,\"_\",label_val))),\n       CONCAT_WS('|' ,collect_set(concat(label_id,\"_\",create_time))),\n       CONCAT_WS('|' ,collect_set(concat(label_id,\"_\",expire_time)))\nFROM db_datastory_trident.all_temp_tags\nWHERE entity_type=497\nAND label_date='2021-01-18'\nGROUP BY entity_id;\n```\n## 查询es\n```json\n{\n  \"took\": 1,\n  \"timed_out\": false,\n  \"_shards\": {\n    \"total\": 5,\n    \"successful\": 5,\n    \"skipped\": 0,\n    \"failed\": 0\n  },\n  \"hits\": {\n    \"total\": 10069,\n    \"max_score\": 1,\n    \"hits\": [\n      {\n        \"_index\": \"trident_test_497\",\n        \"_type\": \"label_default\",\n        \"_id\": \"001522388f3948278e47e047f1b68cf4\",\n        \"_score\": 1,\n        \"_routing\": \"001522388f3948278e47e047f1b68cf4\",\n        \"_parent\": \"001522388f3948278e47e047f1b68cf4\",\n        \"_source\": {\n          \"user_id\": \"001522388f3948278e47e047f1b68cf4\",\n          \"tree_1_label\": \"2083_xjcTest12\",\n          \"tree_1_label_update_time\": \"2083_2021-01-18 00:10:05\",\n          \"tree_1_label_expire_time\": \"2083_2021-01-31 00:00:00\"\n        }\n      },\n      {\n        \"_index\": \"trident_test_497\",\n        \"_type\": \"label_default\",\n        \"_id\": \"00449a157c564f7b957b65fac16bfafd\",\n        \"_score\": 1,\n        \"_routing\": \"00449a157c564f7b957b65fac16bfafd\",\n        \"_parent\": \"00449a157c564f7b957b65fac16bfafd\",\n        \"_source\": {\n          \"user_id\": \"00449a157c564f7b957b65fac16bfafd\",\n          \"tree_1_label\": \"1957_DDD\",\n          \"tree_1_label_update_time\": \"1957_2021-01-18 00:01:20\",\n          \"tree_1_label_expire_time\": \"1957_2100-01-01 00:00:00\"\n        }\n      },\n      {\n        \"_index\": \"trident_test_497\",\n        \"_type\": \"label_default\",\n        \"_id\": \"0080cfcd11b649e0b943eba6d67ecde3\",\n        \"_score\": 1,\n        \"_routing\": \"0080cfcd11b649e0b943eba6d67ecde3\",\n        \"_parent\": \"0080cfcd11b649e0b943eba6d67ecde3\",\n        \"_source\": {\n          \"user_id\": \"0080cfcd11b649e0b943eba6d67ecde3\",\n          \"tree_1_label\": \"1957_DDD\",\n          \"tree_1_label_update_time\": \"1957_2021-01-18 00:01:20\",\n          \"tree_1_label_expire_time\": \"1957_2100-01-01 00:00:00\"\n        }\n      },\n      {\n        \"_index\": \"trident_test_497\",\n        \"_type\": \"label_default\",\n        \"_id\": \"008512c62be741699d16a13e809c9223\",\n        \"_score\": 1,\n        \"_routing\": \"008512c62be741699d16a13e809c9223\",\n        \"_parent\": \"008512c62be741699d16a13e809c9223\",\n        \"_source\": {\n          \"user_id\": \"008512c62be741699d16a13e809c9223\",\n          \"tree_1_label\": \"1957_DDD\",\n          \"tree_1_label_update_time\": \"1957_2021-01-18 00:01:20\",\n          \"tree_1_label_expire_time\": \"1957_2100-01-01 00:00:00\"\n        }\n      },\n      {\n        \"_index\": \"trident_test_497\",\n        \"_type\": \"label_default\",\n        \"_id\": \"008f2445b31e463a8a15f4c2a92e86f4\",\n        \"_score\": 1,\n        \"_routing\": \"008f2445b31e463a8a15f4c2a92e86f4\",\n        \"_parent\": \"008f2445b31e463a8a15f4c2a92e86f4\",\n        \"_source\": {\n          \"user_id\": \"008f2445b31e463a8a15f4c2a92e86f4\",\n          \"tree_1_label\": \"1622_男|1857_男|1984_男|2093_男|2193_男|2306_男\",\n          \"tree_1_label_update_time\": \"1622_2021-01-18 00:22:46|1857_2021-01-18 00:13:23|1984_2021-01-18 00:16:03|2093_2021-01-18 01:01:43|2193_2021-01-18 00:54:38|2306_2021-01-18 01:42:46\",\n          \"tree_1_label_expire_time\": \"1622_2100-01-01 00:00:00|1857_2100-01-01 00:00:00|1984_2100-01-01 00:00:00|2093_2100-01-01 00:00:00|2193_2100-01-01 00:00:00|2306_2100-01-01 00:00:00\"\n        }\n      },\n      {\n        \"_index\": \"trident_test_497\",\n        \"_type\": \"label_default\",\n        \"_id\": \"00e5f18ba0444aa3968b6c226a59212d\",\n        \"_score\": 1,\n        \"_routing\": \"00e5f18ba0444aa3968b6c226a59212d\",\n        \"_parent\": \"00e5f18ba0444aa3968b6c226a59212d\",\n        \"_source\": {\n          \"user_id\": \"00e5f18ba0444aa3968b6c226a59212d\",\n          \"tree_1_label\": \"1954_DD\",\n          \"tree_1_label_update_time\": \"1954_2021-01-18 00:05:44\",\n          \"tree_1_label_expire_time\": \"1954_2100-01-01 00:00:00\"\n        }\n      },\n      {\n        \"_index\": \"trident_test_497\",\n        \"_type\": \"label_default\",\n        \"_id\": \"00ea8cbe08a64b74b205f20f13047fb5\",\n        \"_score\": 1,\n        \"_routing\": \"00ea8cbe08a64b74b205f20f13047fb5\",\n        \"_parent\": \"00ea8cbe08a64b74b205f20f13047fb5\",\n        \"_source\": {\n          \"user_id\": \"00ea8cbe08a64b74b205f20f13047fb5\",\n          \"tree_1_label\": \"1957_DDD\",\n          \"tree_1_label_update_time\": \"1957_2021-01-18 00:01:20\",\n          \"tree_1_label_expire_time\": \"1957_2100-01-01 00:00:00\"\n        }\n      },\n      {\n        \"_index\": \"trident_test_497\",\n        \"_type\": \"label_default\",\n        \"_id\": \"010ccd76f83e4d4ea90714eab2b82b81\",\n        \"_score\": 1,\n        \"_routing\": \"010ccd76f83e4d4ea90714eab2b82b81\",\n        \"_parent\": \"010ccd76f83e4d4ea90714eab2b82b81\",\n        \"_source\": {\n          \"user_id\": \"010ccd76f83e4d4ea90714eab2b82b81\",\n          \"tree_1_label\": \"1953_xdd_标签任务1|1957_DDD\",\n          \"tree_1_label_update_time\": \"1953_2021-01-18 00:05:37|1957_2021-01-18 00:01:20\",\n          \"tree_1_label_expire_time\": \"1953_2100-01-01 00:00:00|1957_2100-01-01 00:00:00\"\n        }\n      },\n      {\n        \"_index\": \"trident_test_497\",\n        \"_type\": \"label_default\",\n        \"_id\": \"010ce418ee5c4f22b92482335885f2ff\",\n        \"_score\": 1,\n        \"_routing\": \"010ce418ee5c4f22b92482335885f2ff\",\n        \"_parent\": \"010ce418ee5c4f22b92482335885f2ff\",\n        \"_source\": {\n          \"user_id\": \"010ce418ee5c4f22b92482335885f2ff\",\n          \"tree_1_label\": \"1953_xdd_标签任务1|2083_xjcTest12\",\n          \"tree_1_label_update_time\": \"1953_2021-01-18 00:05:37|2083_2021-01-18 00:10:05\",\n          \"tree_1_label_expire_time\": \"1953_2100-01-01 00:00:00|2083_2021-01-31 00:00:00\"\n        }\n      },\n      {\n        \"_index\": \"trident_test_497\",\n        \"_type\": \"label_default\",\n        \"_id\": \"011a3638369542f39a2b40a012a1212a\",\n        \"_score\": 1,\n        \"_routing\": \"011a3638369542f39a2b40a012a1212a\",\n        \"_parent\": \"011a3638369542f39a2b40a012a1212a\",\n        \"_source\": {\n          \"user_id\": \"011a3638369542f39a2b40a012a1212a\",\n          \"tree_1_label\": \"1641_客户有下单|1780_客户有下单|1876_客户有下单|1953_xdd_标签任务1|1971_wce|2003_客户有下单|2112_客户有下单|2212_客户有下单|2325_客户有下单\",\n          \"tree_1_label_update_time\": \"1641_2021-01-18 00:48:54|1780_2021-01-18 00:14:47|1876_2021-01-18 00:38:08|1953_2021-01-18 00:05:40|1971_2021-01-18 00:02:37|2003_2021-01-18 00:40:17|2112_2021-01-18 01:26:53|2212_2021-01-18 01:21:08|2325_2021-01-18 02:05:59\",\n          \"tree_1_label_expire_time\": \"1641_2100-01-01 00:00:00|1780_2100-01-01 00:00:00|1876_2100-01-01 00:00:00|1953_2100-01-01 00:00:00|1971_2100-01-01 00:00:00|2003_2100-01-01 00:00:00|2112_2100-01-01 00:00:00|2212_2100-01-01 00:00:00|2325_2100-01-01 00:00:00\"\n        }\n      }\n    ]\n  }\n}\n```\n\n## 统计\n### 标签覆盖人数\n```bash\nGET trident_test_497/label_default/_search\n{\n  \"query\": {\n    \"match\": {\n      \"tree_1_label\": \"1780_客户有下单\"\n    }\n  }\n}\n```\n### 树覆盖人数\n```bash\nGET trident_test_497/label_default/_search\n{\n  \"query\": {\n    \"exists\":{\n      \"field\":\"tree_1_label\"\n    }\n  }\n}\n```\n### 总人数\n```bash\nGET trident_test_497/info/_search\n\n```\n## 刷数据进es（单个标签）\n```sql\nCREATE EXTERNAL TABLE db_datastory_trident.tmp_trident_es_543_1_label_3275(user_id string,tree_1_label string,tree_1_label_update_time string,tree_1_label_expire_time string) \nSTORED BY 'org.elasticsearch.hadoop.hive.EsStorageHandler' \nTBLPROPERTIES(\n\"es.nodes\"=\"dev1:9203,dev1:9204\",\n\"es.write.operation\"=\"upsert\",\n\"es.update.retry.on.conflict\"=\"10\",\n\"es.resource\"=\"trident_test_497/label_default\",\n\"es.mapping.id\"=\"user_id\",\n\"es.mapping.parent\"=\"user_id\",\n\"es.mapping.routing\"=\"user_id\",\n\"es.mapping.names\"=\"user_id:user_id,tree_1_label:tree_1_label,tree_1_label_update_time:tree_1_label_update_time,tree_1_label_expire_time:tree_1_label_expire_time\"\n);\n\n\nINSERT INTO TABLE db_datastory_trident.tmp_trident_es_543_1_label_3275\nSELECT entity_id,\n       CONCAT_WS('|' ,collect_set(concat(label_id,\"_\",label_val))),\n       CONCAT_WS('|' ,collect_set(concat(label_id,\"_\",create_time))),\n       CONCAT_WS('|' ,collect_set(concat(label_id,\"_\",expire_time)))\nFROM db_datastory_trident.all_temp_tags\nWHERE entity_type=497\nAND label_date='2021-01-18'\nAND label_id=3275\nGROUP BY entity_id;\n\nSELECT entity_id,\n       label_val,\n       update_time\nFROM tmp_trident_es_543_1_label_3275 tmp \nLATERAL VIEW explode(tree_1_label) AS label_val \nLATERAL VIEW explode(tree_1_label_update_time) AS update_time \nLIMIT 10;\n\n\n\n```","tags":["trident label 标签"],"categories":["trident"]},{"title":"标签体系改造-TEST-nested","url":"/2021/01/19/标签体系改造-TEST-nested/","content":"## 创建mapping并插入数据 \n```bash\nPUT test4\n{\n  \"mappings\": {\n    \"label_default\": {\n      \"_all\": {\n        \"enabled\": false\n      },\n      \"dynamic_templates\": [\n        {\n          \"time\": {\n            \"match\": \"*_time\",\n            \"match_mapping_type\": \"string\",\n            \"mapping\": {\n              \"format\": \"strict_date_optional_time||yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis\",\n              \"type\": \"date\"\n            }\n          }\n        },\n        {\n          \"timestamp\": {\n            \"match\": \"*_time\",\n            \"match_mapping_type\": \"long\",\n            \"mapping\": {\n              \"format\": \"strict_date_optional_time||epoch_millis\",\n              \"type\": \"date\"\n            }\n          }\n        },\n        {\n          \"default\": {\n            \"match\": \"*\",\n            \"match_mapping_type\": \"string\",\n            \"mapping\": {\n              \"type\": \"keyword\"\n            }\n          }\n        }\n      ],\n      \"properties\": {\n        \"tree_1\": {\n          \"type\": \"nested\",\n          \"properties\": {\n            \"expire_time\": {\n              \"type\": \"date\"\n            },\n            \"id\": {\n              \"type\": \"long\"\n            },\n            \"update_time\": {\n              \"type\": \"date\"\n            },\n            \"value\": {\n              \"type\": \"text\",\n              \"fields\": {\n                \"keyword\": {\n                  \"type\": \"keyword\",\n                  \"ignore_above\": 256\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n}\n\nPUT test4/label_default/34de9d4d3da142348ad8f4e23e05d71c/_create\n{\n  \"tree_1\": [\n    {\n      \"id\": 1641,\n      \"value\": \"客户有下单\",\n      \"update_time\": 1610990713000,\n      \"expire_time\": 4102416000000\n    }\n  ]\n}\n\n\nPUT test4/label_default/28a47dc2f4814e70b95b4f69bd592bbd/_create\n{\n  \"tree_1\": [\n    {\n      \"id\": 1641,\n      \"value\": \"客户有下单\",\n      \"update_time\": 1610990713000,\n      \"expire_time\": 4102416000000\n    },\n    {\n      \"id\": 1953,\n      \"value\": \"xdd_标签任务1\",\n      \"update_time\": 1610990713000,\n      \"expire_time\": 4102416000000\n    }\n  ]\n}\n```\n\n## hive 刷数据到 es\n```sql\n# es.mapping.parent和es.mapping.routing是针对父子文档的设置\nDROP TABLE IF EXISTS db_datastory_trident.hive2es_test4;\n\nCREATE EXTERNAL TABLE db_datastory_trident.hive2es_test4(user_id string,tree array<struct<id:bigint,value:string,update_time:timestamp,expire_time:timestamp>>) \nSTORED BY 'org.elasticsearch.hadoop.hive.EsStorageHandler' \nTBLPROPERTIES(\"es.nodes\"=\"dev1:9203,dev1:9204\", \"es.write.operation\"=\"upsert\", \"es.update.retry.on.conflict\"=\"10\", \"es.resource\"=\"test4/label_default\", \"es.mapping.id\"=\"user_id\", \"es.mapping.names\"=\"user_id:user_id,tree:tree_1\");\n\n# collect为UDAF，用于将group by外的字段组成一个array。（collect_set增强）\n# add jar hdfs:///user/hive/ds-trident-serv-etl-1.2.1.1-SNAPSHOT.jar;\n# drop temporary function if exists collect;\n# create temporary function collect as 'com.datastory.trident.serv.udf.CollectUDAF';\n\n\nINSERT INTO TABLE db_datastory_trident.hive2es_test4\nSELECT entity_id ,\n       collect(named_struct(\"id\", label_id,\"value\", label_val, \"update_time\", create_time,\"expire_time\",expire_time)) AS tree\nFROM all_temp_tags where entity_type=497 and label_date='2021-01-21' \nGROUP BY entity_id;\n\n\n# 考虑all_temp_tags中增加tree的分区，entity_type为1级分区，tree为2级分区，label_date为3级分区，以树为单位刷数据\n```\n## 更新单个标签\n```sql\n1953\n\n#INSERT INTO TABLE db_datastory_trident.hbase_label_415_temp_1479 SELECT entity_id,label_val,create_time,expire_time FROM db_datastory_trident.all_temp_tags WHERE entity_type=415 AND label_date='#{#cur_date}' AND label_id=1479;\n\nDROP TABLE IF EXISTS db_datastory_trident.tmp_trident_es_497_label_1953;\n\nCREATE EXTERNAL TABLE db_datastory_trident.tmp_trident_es_497_label_1953(user_id string,id bigint,value string,update_time timestamp,expire_time timestamp) \nSTORED BY 'org.elasticsearch.hadoop.hive.EsStorageHandler' \nTBLPROPERTIES(\n\"es.nodes\"=\"dev1:9203,dev1:9204\",\n\"es.write.operation\"=\"upsert\",\n\"es.update.retry.on.conflict\"=\"10\",\n\"es.resource\"=\"test4/label_default\",\n\"es.mapping.id\"=\"user_id\"\n\"es.mapping.names\"=\"user_id:user_id,id:tree_1.id,value:tree_1.value,update_time:tree_1.update_time,expire_time:tree_1.expire_time\"\n);\n\nDROP TABLE IF EXISTS db_datastory_trident.tmp_trident_es_497_label_1953;\nCREATE EXTERNAL TABLE db_datastory_trident.tmp_trident_es_497_label_1953(user_id string,tree struct<id:bigint,value:string,update_time:timestamp,expire_time:timestamp>) \nSTORED BY 'org.elasticsearch.hadoop.hive.EsStorageHandler' \nTBLPROPERTIES(\"es.nodes\"=\"dev1:9203,dev1:9204\", \"es.write.operation\"=\"upsert\", \"es.update.retry.on.conflict\"=\"10\", \"es.resource\"=\"test4/label_default\", \"es.mapping.id\"=\"user_id\", \"es.mapping.names\"=\"user_id:user_id,id:id,value:value,update_time:update_time,expire_time:expire_time\");\n\n\nINSERT INTO TABLE db_datastory_trident.tmp_trident_es_497_label_1953\n\n select user_id,label from (SELECT user_id,tree from db_datastory_trident.tmp_trident_es_497_label_1953 where user_id in (SELECT entity_id as user_id FROM db_datastory_trident.all_temp_tags WHERE entity_type=497 AND label_date='2021-01-21' AND label_id=1953)) as tmp\n lateral view explode(tree) col as label;\n SELECT entity_id as user_id,1953 as id,label_val as value,create_time as update_time,expire_time FROM db_datastory_trident.all_temp_tags WHERE entity_type=497 AND label_date='2021-01-21' AND label_id=1953;\n\n\nSELECT pageid, adid \n    FROM pageAds LATERAL VIEW explode(adid_list) adTable AS adid;\n\nselect user_id,label from db_datastory_trident.tmp_trident_es_497_label_1953  LATERAL VIEW explode(tree) tree_table as label limit 10;\n\n```\n## hive 刷数据到 HBase\n\n## 查询\n注意查询需要用nested类型\n```bash\nGET test4/_search\n{\n  \"query\": {\n    \"nested\": {\n      \"path\": \"tree_1\",\n      \"query\": {\n        \"term\": {\n          \"tree_1.id\": {\n            \"value\": \"1953\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n","tags":["trident label 标签"],"categories":["trident"]},{"title":"标签体系改造","url":"/2021/01/19/标签体系改造/","content":"# 标签体系ES存储方案（es v5）\n\n## 设置分词器\n```json\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"vertical\": {\n          \"type\": \"pattern\",\n          \"parttern\": \"\\\\|\"\n        }\n      }\n    }\n  }\n}\n```\n\n## index\n每个treeType为一个index，名称为trident\\_es\\_{treeTypeId}\n\n## type\n### info\n对应打标签对象的物料表\n\n### label\n存储标签\n\n>**info和label为父子文档**\n\n## schema\n### info\n和物料表字段类型保持一致，string类型的都为keyword\n\n### label\nlabel中有多个properties，设置索引模板\n\n每个标签树对应三个字段：tree\\_{treeId}\\_label，tree\\_{treeId}\\_label_expire_time，tree\\_{treeId}\\_label_update_time，每个字段设置类型为text，设置分词器为\\\\|\n\n字段中存储多个标签，每个标签用｜分割\n```json\n{\n     \"_source\":{\n          \"tree_1_label\":\"1_男｜2_四川|3_中国\",\n          \"tree_1_label_expire_time\":\"1_2100-01-01T00:00:00+08:00|2_2100-01-01T00:00:00+08:00|3_2100-01-01T00:00:00+08:00\",\n          \"tree_1_label_update_time\":\"1_2100-01-01T00:00:00+08:00|2_2100-01-01T00:00:00+08:00|3_2100-01-01T00:00:00+08:00\"\n     }\n}\n```\n\n## 涉及改动\n### 写入\n#### 原整体写入流程\n+ 根据标签规则设置，生成相应的打标签sql（基于hive）\n+ 将标签结果写入到hive中的all_temp_tag里（竖表，分区表）\n```sql\nCREATE TABLE db_datastory_trident.all_temp_tags(\n     entity_id string COMMENT '实体ID',\n     label_val string COMMENT '标签值',\n     expire_time timestamp COMMENT '过期时间，默认为unix_timestamp()',\n     create_time timestamp COMMENT '创建时间，默认为unix_timestamp()'\n) PARTITIONED BY (entity_type INT,label_date DATE,label_id INT)\n ROW FORMAT DELIMITED FIELDS TERMINATED BY '\\001' STORED AS textfile;\n\nINSERT OVERWRITE TABLE db_datastory_trident.all_temp_tags PARTITION(entity_type=543, label_date='#{#cur_date}', label_id=3275)\nSELECT tdm_cdp_tdm_user_91510124MA61X5CT68.user_id AS entity_id,\n       '覆盖四川人群' AS label_val,\n       FROM_UNIXTIME(4102416000) AS expire_time,\n       FROM_UNIXTIME(UNIX_TIMESTAMP()) AS create_time\nFROM tdm_cdp.tdm_user_91510124MA61X5CT68 AS tdm_cdp_tdm_user_91510124MA61X5CT68\nWHERE tdm_cdp_tdm_user_91510124MA61X5CT68.user_id IS NOT NULL\n  AND tdm_cdp_tdm_user_91510124MA61X5CT68.`province`='四川省';\n\n```\n+ 将结果竖表转成横表，刷到hbase和es中\n```sql\n## hbase_label_{treeTypeId}_temp_{labelId}\nDROP TABLE IF EXISTS db_datastory_trident.hbase_label_543_temp_3275;\n\nCREATE EXTERNAL TABLE db_datastory_trident.hbase_label_543_temp_3275(user_id string,label_3275 string,label_3275_update_time TIMESTAMP,label_3275_expire_time TIMESTAMP) STORED BY 'org.apache.hadoop.hive.hbase.HBaseStorageHandler' WITH SERDEPROPERTIES ( 'hbase.columns.mapping'=':key,labels:label_3275,labels:label_3275_update_time,labels:label_3275_expire_time') TBLPROPERTIES ( 'hbase.mapred.output.outputtable'='db_datastory_trident.hbase_label_543', 'hbase.table.name'='db_datastory_trident.hbase_label_543');\n\nINSERT INTO TABLE db_datastory_trident.hbase_label_543_temp_3275\nSELECT entity_id,\n       label_val,\n       create_time,\n       expire_time\nFROM db_datastory_trident.all_temp_tags\nWHERE entity_type=543\n  AND label_date='#{#cur_date}'\n  AND label_id=3275;\n\n## tmp_trident_es_{treeTypeId}_label_{labelId}\nDROP TABLE IF EXISTS db_datastory_trident.tmp_trident_es_543_label_3275;\n\nCREATE EXTERNAL TABLE db_datastory_trident.tmp_trident_es_543_label_3275(user_id string,label_3275 string,label_3275_update_time TIMESTAMP,label_3275_expire_time TIMESTAMP) STORED BY 'org.elasticsearch.hadoop.hive.EsStorageHandler' TBLPROPERTIES(\"es.nodes\"=\"xdp-prod-es1:9200\", \"es.write.operation\"=\"upsert\", \"es.update.retry.on.conflict\"=\"10\", \"es.resource\"=\"trident_es_543/label_default\", \"es.mapping.id\"=\"user_id\", \"es.mapping.parent\"=\"user_id\", \"es.mapping.routing\"=\"user_id\", \"es.mapping.names\"=\"user_id:user_id,label_3275:label_3275,label_3275_update_time:label_3275_update_time,label_3275_expire_time:label_3275_expire_time\");\n\nINSERT INTO TABLE db_datastory_trident.tmp_trident_es_543_label_3275\nSELECT user_id,\n       label_3275,\n       label_3275_update_time,\n       label_3275_expire_time\nFROM db_datastory_trident.hbase_label_543_temp_3275;\n\nDROP TABLE IF EXISTS db_datastory_trident.hbase_label_543_temp_3275;\nDROP TABLE IF EXISTS db_datastory_trident.tmp_trident_es_543_label_3275;\n```\n\n#### 改动后的写入流程\n+ 根据标签规则设置，生成相应的打标签sql（基于hive） ==> 不变\n+ 将标签结果写入到hive中的all_temp_tag里（竖表，分区表） ==> 分区增加tree\n```sql\nCREATE TABLE db_datastory_trident.all_temp_tags(\n     entity_id string COMMENT '实体ID',\n     label_val string COMMENT '标签值',\n     expire_time timestamp COMMENT '过期时间，默认为unix_timestamp()',\n     create_time timestamp COMMENT '创建时间，默认为unix_timestamp()'\n) PARTITIONED BY (entity_type INT,tree_id INT,label_date DATE,label_id INT)\n ROW FORMAT DELIMITED FIELDS TERMINATED BY '\\001' STORED AS textfile;\n\nINSERT OVERWRITE TABLE db_datastory_trident.all_temp_tags PARTITION(entity_type=543, tree_id=1, label_date='#{#cur_date}', label_id=3275)\nSELECT tdm_cdp_tdm_user_91510124MA61X5CT68.user_id AS entity_id,\n       '覆盖四川人群' AS label_val,\n       FROM_UNIXTIME(4102416000) AS expire_time,\n       FROM_UNIXTIME(UNIX_TIMESTAMP()) AS create_time\nFROM tdm_cdp.tdm_user_91510124MA61X5CT68 AS tdm_cdp_tdm_user_91510124MA61X5CT68\nWHERE tdm_cdp_tdm_user_91510124MA61X5CT68.user_id IS NOT NULL\n  AND tdm_cdp_tdm_user_91510124MA61X5CT68.`province`='四川省';\n\n```\n+ 将结果竖表转成横表，刷到hbase和es中 ==> 修改逻辑，将多字段拼接成字符串\n**跑单个标签时，也走这种逻辑，性能问题？**\n```sql\n## hbase_label_{treeTypeId}_{treeId}_temp\nDROP TABLE IF EXISTS db_datastory_trident.hbase_label_543_1_temp_3275;\n\n## 新增标签树时，需要alterhbase表，增加相应字段（3个）\nCREATE EXTERNAL TABLE db_datastory_trident.hbase_label_543_1_temp_3275(user_id string,tree_1_label string,tree_1_label_update_time string,tree_1_label_expire_time string) STORED BY 'org.apache.hadoop.hive.hbase.HBaseStorageHandler' WITH SERDEPROPERTIES ( 'hbase.columns.mapping'=':key,labels:tree_1_label,labels:tree_1_label_update_time,labels:tree_1_label_expire_time') TBLPROPERTIES ( 'hbase.mapred.output.outputtable'='db_datastory_trident.hbase_label_543', 'hbase.table.name'='db_datastory_trident.hbase_label_543');\n\nINSERT INTO TABLE db_datastory_trident.hbase_label_543_1_temp_3275\nSELECT entity_id,\n       CONCAT_WS('|' ,collect_set(concat(label_id,\"_\",label_val))),\n       CONCAT_WS('|' ,collect_set(concat(label_id,\"_\",create_time))),\n       CONCAT_WS('|' ,collect_set(concat(label_id,\"_\",expire_time)))\nFROM db_datastory_trident.all_temp_tags\nWHERE entity_type=543\n  AND tree_id=1\n  AND label_date='#{#cur_date}'\n  GROUP BY entity_id;\n\n\n#00b2d95622fd49c1ba79064ac09842df   1955_标签测试_WSK|1956_teset|1957_DDD|1953_xdd_标签任务1|1970_标签测试_WSK12\n#00b4e84465b8473c9cecb4cf35c41177   1955_标签测试_WSK|1956_teset|1970_标签测试_WSK12\n#00b91497d78e4eefa45cfd87fc3f319d   1955_标签测试_WSK|1956_teset|1957_DDD|1953_xdd_标签任务1|1970_标签测试_WSK12\n\n## tmp_trident_es_{treeTypeId}_{treeId}_label_{labelId}\nDROP TABLE IF EXISTS db_datastory_trident.tmp_trident_es_543_1_label_3275;\n\nCREATE EXTERNAL TABLE db_datastory_trident.tmp_trident_es_543_1_label_3275(user_id string,tree_1_label string,tree_1_label_update_time string,tree_1_label_expire_time string) STORED BY 'org.elasticsearch.hadoop.hive.EsStorageHandler' TBLPROPERTIES(\"es.nodes\"=\"xdp-prod-es1:9200\", \"es.write.operation\"=\"upsert\", \"es.update.retry.on.conflict\"=\"10\", \"es.resource\"=\"trident_es_543/label_default\", \"es.mapping.id\"=\"user_id\", \"es.mapping.parent\"=\"user_id\", \"es.mapping.routing\"=\"user_id\", \"es.mapping.names\"=\"user_id:user_id,tree_1_label:tree_1_label,tree_1_label_update_time:tree_1_label_update_time,tree_1_label_expire_time:tree_1_label_expire_time\");\n\nINSERT INTO TABLE db_datastory_trident.tmp_trident_es_543_1_label_3275\nSELECT user_id,\n       tree_1_label,\n       tree_1_label_update_time,\n       tree_1_label_expire_time\nFROM db_datastory_trident.hbase_label_543_temp_3275;\n\nDROP TABLE IF EXISTS db_datastory_trident.hbase_label_543_1_temp_3275;\nDROP TABLE IF EXISTS db_datastory_trident.tmp_trident_es_543_1_label_3275;\n```\n\n**强制要求标签名中不能有“|”**\n\n#### merge相关\n\n### 修改\n#### 原\n#### 改后\n\n### 删除\n#### 原\n#### 改后\n\n### 查询\n#### 原\n#### 改后\n\n# 人群包\n修改相应的查询，仍然是has_child+query，query中采用bool+match的形式\n<font color=\"red\">涉及到标签过期的话，采用script？</font>\n\n# 待确认\n- [x] leo表达式是否支持转换es的match请求 ==> 支持 详见[Leo表达式汇总文档](https://wiki.datastory.com.cn/x/AOM4AQ)\n```json\n{\n    \"must\": [\n        \"1##match(内容,中国)\",\n        \"2##match(内容,贸易战)\"\n    ],\n    \"mustNot\": [],\n    \"boolExpression\": \"1 OR 2\"\n}\n``` \n- [ ] 更新时的性能问题\n    更新某个标签时，因为是字符串，所以不能直接update，需要用script的方式去更新。将值取出来，split，找到对应的标签，update取值\n\n\n> <font color=\"red\">数组方案宣告失败。[参考官网说明](https://www.elastic.co/guide/en/elasticsearch/reference/5.6/array.html)</font>\n# 方案2 数组\n```bash\nPUT test2/label_default/19b2a580d86946a7b886ac2e79b581f2/_create\n{\n  \"tree_2\":[\n      \"1641,客户有下单,1610990713000,4102416000000\",\n      \"1953,xdd_标签任务1,1610990713000,4102416000000\"\n    ]\n}\n\nPUT test2/label_default/1a0ec7855540498696a1ed50a16e1228/_create\n{\n  \"tree_2\":[\n      \"1641,客户有下单,1610990713000,4102416000000\"    ]\n}\n\n## 更新目前不行\nPOST test2/label_default/_update\n{\n  \"query\": {\n    \"bool\": {\n      \"must\": [\n\n        {\n          \"match\": {\n            \"tree_2\": \"xdd_标签任务1\"\n          }\n        }\n      ]\n    }\n  },\n  \"script\": {\n    \"source\": \"List<String> source = ctx._source.tree_2; for(int i=0;i<source.size();i++){String[] tmp = source[i].split(\\\",\\\"); tmp[2] = params.updateTime; ctx._source.tree_2[i]=tmp.join(\\\",\\\"); }\",\n    \"params\":{\n      \"updateTime\":1611115065000\n    },\n    \"lang\": \"painless\"\n  }\n}\n```\n# 方案三 nested\n```bash\n\n\n```\n","tags":["trident label 标签"],"categories":["trident"]},{"title":"Elasticsearch-1","url":"/2021/01/19/Elasticsearch-1/","content":"> [巨人的肩膀1](https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MzI2NDY1MTA3OQ==&action=getalbum&album_id=1340073242396114944&scene=173&from_msgid=2247484661&from_itemidx=1&count=3#wechat_redirect)\n>\n> [巨人的肩膀2](https://blog.csdn.net/weixin_42340670/article/details/111627244)\n## es文档模型\n![es文档存储模型](/image/Elasticsearch-1-1611032343670.png)\nsegment 段 --> Lucene 索引 --> shard 分片 --> index \n\n### 涉及操作\n+ 创建索引 PUT /indexname\n+ 设置分片数量 PUT settings number_of_shards\n+ 设置副本数量 number_of_replicas，主分片和副本分片必然在不同节点上\n+ 删除索引 DELETE /indexname\n+ 压缩 shrink\n+ 段合并 force_merge\n**注意：**\n+ **分片一旦创建，不可以修改分片数量。**\n+ **每个分片官方推荐大小为20-40G**\n+ **每个段内部文档ID为java的整型，即2^31，总文档数量最大为Integer.MAXVALUE-128=21.4亿条，force_merge后会合并成一个大段**\n+ **es中的段只能不断新增和合并（多个小的合并成大的），所以实际上delete_by_query只是对删除的document做标记，触发merge的时候才会真正删除（多个小段合并成一个大段，删除的文档不会被复制到新段里）**\n\n### 分片如何设置\n+ 设置多少分片？\n    - 单分片建议20-40GB\n    - 预估数据总量，即每天新增多少数据，需要存储多久数据\n    - 结合上述两点，考虑滚动索引+索引别名形式，分多个索引存储\n    - 集群规模多大？存储和内存有多少\n+ 设置多少副本\n    - 集群规模>2时，建议至少副本为1\n\n### 写性能\n\n####  mapping如何设置\n\n+ 哪些字符串定义为全文检索字段\n+ 哪些字段包含数字、日期或者地理位置\n+ 定义日期格式（时间戳还是日期类型等）\n+ 用于控制动态添加字段的映射的自定义规则\n\n**注意事项**\n![mapping注意事项](/image/Elasticsearch-1-1611033751582.png)\n+ es支持增加字段\n```bash\nPUT new_index\n  {\n    \"mappings\": {\n      \"_doc\": {\n        \"properties\": {\n          \"status_code\": {\n            \"type\":       \"keyword\"\n          }\n        }\n      }\n    }\n  }\n```\n+ es不支持直接删除字段\n+ es不支持直接修改字段\n+ es不支持直接修改字段类型\n---\n曲线救国方式：reindex。数据量大时会有性能问题。\n\n---\n\nmapping字段设置流程\n\n一般实战建议采用静态mapping，即手动设置mapping。\n+ 可控\n+ 节省存储空间（默认string是text+keyword，实际义务不一定需要）\n\n```mermaid\ngraph TD\nstart[何种数据类型]-->index{是否需要检索}\nindex--是-->indexTrue[\"index:true<br/>index_options:<br/>docs;freqs;positions;offsets\"]\nindex--否-->indexFalse[index:false]\nindex-->sort{是否需要排序和聚合分析}\nsort--否-->sortFalse[\"doc_value=false<br/>fielddata=false（默认）<br/>节省存储\"]\nsort-->persist{是否需要另行存储}--是-->persistTrue[\"store=true<br/>source=false<br/>配合使用\"]\n```\n+ 字符串类型，需要分词=text，否则keyword\n+ 枚举类型，基于性能，用keyword，即使是整型\n+ 数字类型，尽量选择贴近大小的类型 int long float double等\n+ 其他类型，bool date 地理位置\n核心参数含义：\n![核心参数](/image/Elasticsearch-1-1611035649026.png)\n\n### 读性能\n\n#### 不需要评分则用filter查询\n\n```json\n{\n  \"query\": { \n    \"bool\": { \n      \"filter\": [ // 所有的查询都封装到filter上下文里 \n        {...}, \n        {...}\n      ]\n    }\n  }\n}\n\n```\n\n\n\n#### 设置filter_path只返回必要的业务字段\n\n使用es的search api，默认返回的结果里面包含的信息比较多。\n\n```json\n{\n    \"took\": 1, // es内部的查询耗时，毫秒\n    \"timed_out\": false, // 查询是否超时\n    \"_shards\":{ // 和本次查询相关的分片信息\n        \"total\" : 1, // 一共涉及到几个分片\n        \"successful\" : 1, // 查询成功的分片个数\n        \"skipped\" : 0, // 跳过的（忽略的）分片个数\n        \"failed\" : 0 // 查询失败的分片个数\n    },\n    \"hits\":{ // 查询结果（命中结果）\n        \"total\" : 10, // 满足条件的文档个数\n        \"hits\" : [ // 满足条件的文档\n            {\n                \"_index\" : \"user_tag\", // 文档所属的索引\n                \"_type\" : \"default\", // 文档所属的类型\n                \"_id\" : \"131\", // 文档id\n                \"_score\": 0, // 评分（filter查询，该值所有文档都是一样的）\n                \"_source\" : { // 文档的数据（这里才是业务最关心的数据）\n                    \"user_id\" : 131,\n                    \"frequency\": 0,\n                    \"lifecycle\": 1,\n                    \"contribution\": 0,\n                    \"first_order_time\": 0,\n                    \"monetary\": 0,\n                    \"recency\": 2,\n                    \"total_amount\": 0,\n                    ....\n                }\n            }\n            ... // 其他文档\n        ]\n    }\n}\n\n```\n\n针对于上面的返回结果，大部分情况下业务逻辑只关心：\n\n- hits.total（满足条件的总数）\n- hits.hits._source（满足条件的文档数据）\n  这两部分数据。其他的数据不需要，可以没必要返回。和_source同层级的\"_index/_type/_id/_score\"，这些属性每个文档上都会存在，在大批量循环查询的场景下（每批几百上千，循环很多次），这部分数据的传输和解析耗时也是不容小觑的。这时候就可以通过filter_path指定只返回需要的属性。\n\n```javascript\n\"filter_path\":\"hits.total,hits.hits._source\"\n//注意：filter_path的设置，是一个逗号分隔的字符串。属性名称要包含从顶层节点到自己的所有节点。\n//通过这个设置后，返回的结果就是下面的样子：\n{\n    \"hits\":{ // 查询结果（命中结果）\n        \"total\" : 10, // 满足条件的文档个数\n        \"hits\" : [ // 满足条件的文档\n            {\n                \"_source\" : { // 文档的数据（这里才是业务最关心的数据）\n                    \"user_id\" : 131,\n                    ...\n                }\n            }\n            {\n                \"_source\": {\n                    ...\n                }\n            }\n            ... // 其他文档\n        ]\n    }\n}\n```\n\n#### 设置_source只返回必要的列\n\n```json\n{\n    \"query\" : {\n        ...\n    },\n    \"_source\": [\"user_id\"]\n}\n```\n\n#### 不关心文档内容，_source置为false\n\n在上一项内容中介绍过，如果我们业务需求，只是根据各种标签组合来查询用户的id，那么我们最终需要的业务数据只有用户id一项而已。可以通过《\"_source\": [“user_id”]》这样的设置方式来精简返回结果。在es内部，每个文档都有一个元数据属性\"_id\"，是文档的唯一标识，可以指定业务上的具有唯一特性的数值，也可以让es自动生成。es的官方讲，自动生成id的算法可以保证唯一，在写入时性能会比较好。如果是业务自定义的id（比如以用户id作为文档id），在新增文档时，都会去校验一下id的唯一性。在用户画像业务上，用户数据是一个持续递增的过程，新的用户注册，就应该会插入一条文档，用户信息变更，就应该修改对应文档。为了便于文档的修改，往往都会以业务上的唯一主键来作为文档的id。所以一条文档的数据信息类似如下：\n\n```json\n{\n    \"_index\" : \"user_tag\",\n    \"_type\" : \"default\",\n    \"_id\" : \"131\", // 文档id，和用户id一致\n    \"_score\": 0, \n    \"_source\" : { \n        \"user_id\" : 131, // 用户id，和文档id一致。\n        ....\n    }\n}\n\n```\n\n看完上面的数据，再来回顾我们谈论的只返回用户id的需求。我们完全就可以不依赖_source的内容了，只需返回_id就可以了。要达到这样的效果，只需要通过类似下面的设置\n\n```javascript\n\"filter_path\":\"hits.total,hits.hits._id\"\n//就可以得到如下的返回结果\n{\n    \"hits\":{\n        \"total\" : 10,\n        \"hits\" : [\n            {\n                \"_id\" : 131\n            }\n            {\n                \"_id\": 132\n            }\n            ... // 其他文档\n        ]\n    }\n}\n```\n\nhits里的数据结果要比第三点设置_source中讨论的最后的返回结果还要精简。但是这只是第一步，返回内容的精简的确会节省带宽占用，减少网络IO，但如果每批次只返回几百上千条这样的数据，性能优势不会特别明显，起码不至于有几十或者上百毫秒的性能差异。\n\n所以，接下来才是重点，es的查询分为两个阶段，query阶段、fetch阶段。\n\n- query阶段：每个分片会返回满足条件的文档id、以及评分，返回到协调节点。\n- fetch阶段：协调节点整合各个节点返回的数据，最后确定出哪些文档id对应的文档需要返回给客户端，然后将这些文档id，按所在分片分组后，发送给各个分片对应的查询请求，获取最终的文档。这一阶段取回的文档越多，取回的文档属性越多，性能也会越差。\n\n***所有分片的文档数据获取成功后，在基于客户端的查询设置，统一打包返回给客户端。***\n\n> 关于filter_path，其实是在query、fetch两个阶段都完成后，最后一步打包阶段，把多余的信息排除掉了而已。所以当我们只需要文档id的时候，根本就不需要让es去执行fetch阶段的流程，因为query阶段满足条件的文档id就已经都得到了。\n\n***想要避免fetch阶段的流程，只需要在查询请求中，将_source置为false即可。***\n\n```javascript\n{\n    \"query\" : {\n        ...\n    },\n    \"_source\": false\n}\n```\n\n> 因数据体量、硬件性能、分页大小都存在差异，在不同的场景下，性能的提升幅度肯定会有差异，这个优化手段应该可以将响应性能缩减几十甚至上百毫秒。\n\n#### 避免深分页\n\n深分页这个问题无论是在传统的关系型数据库如mysql，还是我们现在讨论的es，都会面临性能问题。分页越深，性能越差。尽管性能会变差，但是传统的关系型数据库，也不会限制分页的深度。\n但es会，超过他限定的深度，es会返回异常。\n\n```ini\nindex.max_result_window : 10000\n```\n\nmax_result_window默认值是10000，这个值的意思是分页查询时，from + size 的值如果超过 10000。 那么将查询失败。\n\n- 1000, 9001：从第1000条再往后查9001条，超出10000限制。\n- 9000, 1001：从第9000条再往后查1001条，超出10000限制。\n\n这就意味着，如果你的某个查询，满足条件的超过10000个文档，那么你想用分页把这些文档循环获取出来，是不可能的。因为你最多只能分页取出来10000个。所以一个简单粗暴的方式，就是调大这个设置。但是es以及业内最佳实践其实都不建议这样做。es会建议用scroll api的方式来滚动获取所有的数据。\n\nscroll就像是一个可以中途下车，但不能中途上车的列车。你一定是从头开始，但可以自由决定何时终止查询，哪怕数据还未取完。但是你不能从中间开始。它比较适合后台任务类型的、全量去取数场景，不适合前端交互类、跳页查询的场景。\n\n当然除了scroll，还可以基于自己业务数据上的具有唯一性的数据字段，进行偏移查询（gt、lt），也可以实现全量取数。那么遗留下来的跳页查询怎么办，还是无法解决呀？\n\n> 跳页查询，这个问题往往就是产品和业务层面要做一些折衷了。10000条的限制，20条一页，可以分500页。没有几个人会无聊到一直一页一页的翻500次，前几页如果没有他想要的数据，那么他的操作思路肯定就应该是增加搜索条件了。","tags":["elasticsearch"],"categories":["elasticsearch"]},{"title":"标签体系一些坑","url":"/2021/01/15/标签体系一些坑/","content":"# 平台侧\n## 标签树类型\n- [ ] 更新标签树类型的任务（update_tree_type）每晚定时更新，可能不及时\n- [ ] 更新任务可能出错，导致es中info没有数据，但是打标签流程正常，则label_default会有数据。导致 1. 用户平均标签有问题 2. 人群包有问题。（人群包查的info，hasChild）\n- [ ] 物料表的删除、字段变更（包含删除，修改字段吗，修改字段类型等），es的mapping和hbase那边没有更新，某些情况下导致更新标签树类型的任务失败\n- [ ] 迁移集群后，任务失败（除非连得上原来的集群）或数据跟着迁移且avalon跟着更新\n- [ ] 配置\n\n## 标签树\n- [ ] 没有del_flag\n- [ ] 没有删除接口\n- [ ] 在存储方案中没有标签树的信息\n\n## 标签\n- [ ] 深度合并优化\n\n# 业务侧\n## for 领客\n### 通用标签树\n- [ ] 每个租户复制标签树（from 通用标签树）。如果通用标签树还在维护（增删改），租户的标签树怎么同步更新？\n- [ ]\n\n## 标签树类型\n\n## 标签树\n- [ ] 没有统一的前置过滤条件\n","tags":["trident"],"categories":["trident"]},{"title":"标签体系级联更新、删除","url":"/2021/01/12/标签体系级联更新、删除/","content":"# 数据源被删除\n## 典型场景如下\n+ 标签树类型的物料表在不知道的情况下，被人为物理删除了\n+ 迁移集群后，原来的物料表没有跟着迁移，或迁移后，avalon没有更新物料表元信息\n---\n以上情况会导致标签树类型无法再更新物料表，整个打标签流程都受影响。\n\n## 触发机制\n在updateAllTreeType的定时任务中，判断treeType对应的datasource状态是否为green\n\n非green的情况下，\n+ 标签树类型delFlag设置为1（停用）\n+ 树类型下的delFlag=0的labelInfo，设置delFlag=2\n\ngreen的情况下\n+ 标签树类型delFlag设置为1（停用）\n+ 将树类型下的labelInfo，delFlag=4的都设置回的delFlag=0\n---\n⚠️\n\n**labelTreeType：delFlag： 0启用， 1 停用, 2删除**\n**labelInfo：del_flag 0=未删除 1=删除 添加2=临时删除**\n\n# 数据源更新\n## 典型场景如下\n项目还处在开发阶段，字段类型时有改变，如gender字段早期为varchar类型，取值男、女，后续又改成integer，取值0、1.\n\n## 触发机制\n主动更新（接口更新）\n\n### ES 更新\n 删掉原来的info type，直接新生成\n### HBase更新\n disable table ，alter，enable table\n### 数据库更新\nt_trident_tree_type_corpus、t_trident_corpus_field","tags":["trident"],"categories":["trident"]},{"title":"flink table api和flink sql","url":"/2021/01/11/flink-table-api和flink-sql/","content":"# 表（Table）\n+ tableEnvironment可以注册目录Catalog，并可以基于Catalog注册表\n+ 表（Table）是有一个\"标识符\"（identifier）来指定，由3部分组成：Catalog名，数据库（database）名和对象名\n+ 表可以是常规的，也可以是虚拟的（视图，view）\n+ 常规表（Table）一般可以用来描述外部数据，比如文件、数据库表或消息队列的数据，也可以直接从DataStream转换而来\n+ 视图（view）可以从现有表中创建，通常是table API 或者SQL查询的一个结果集\n\n## 创建表\n```scala\ntableEnv\n    .connect(...)       // 定义表的数据来源\n    .withFormat(...)    // 定义数据格式化方法\n    .withSchema(...)    // 定义表结构\n    .createTemporaryTable(\"myTable\"); // 创建临时表（在catalog中注册表）\n```\n","tags":["flink sql"],"categories":["flink sql"]},{"title":"用户画像标签体系3","url":"/2021/01/08/用户画像标签体系3/","content":" 用户画像的核心在于给用户“打标签”，每一个标签通常是人为规定的特征标识，用高度精炼的特征描述一类人，例如年龄、性别、兴趣偏好等，不同的标签通过结构化的数据体系整合，就可与组合出不同的用户画像。\n\n​ 梳理标签体系是实现用户画像过程中最基础、也是最核心的工作，后续的建模、数据仓库搭建都会依赖于标签体系。\n\n​ 为什么需要梳理标签体系，因为不同的企业做用户画像有不同的战略目的，广告公司做用户画像是为精准广告服务，电商做用户画像是为用户购买更多商品，内容平台做用户画像是推荐用户更感兴趣的内容提升流量再变现，金融行业做用户画像是为了寻找到目标客户的同时做好风险的控制。\n\n​ 所以第一步，我们要结合所在的行业，业务去分析我们用户画像的目的。这其实就是战略，我们要通过战略去指引我们最终的方向。\n\n![标签画像](/image/用户画像标签体系1-1610100155452.png)\n\n对于电商企业来说，可能最重要的两个问题就是：\n\n**现有用户- 我的现存用户是谁？为什么买我的产品？他们有什么偏好？哪些用户价值最高？**\n\n**潜在客户- 我的潜在用户在哪儿？他们喜欢什么？哪些渠道能找到他们？获客成本是多少？**\n\n而对于金融企业，还要加上一条：\n\n**用户风险—用户的收入能力怎么样？他们是否有过贷款或者信用卡的逾期？他们的征信有问题吗？**\n\n我们做用户画像的目的也就是根据我们指定的战略方向最终去解决这些问题。\n\n在梳理标签的过程还要紧密的结合我们的数据，不能脱离了数据去空想，当然如果是我们必须要的数据，我们可能需要想办法去获取这些数据，这就是数据采集的问题，我们之后会深入的讨论。\n\n先展示两种常见的标签体系，随后我们将按步骤建立我们的标签体系。\n\n## 电商类标签体系\n![电商类](/image/用户画像标签体系1-1610100324696.png)\n可以看到电商类的标签体系，更关注用户的属性，行为等等信息。那么我们需要的数据也就来源于用户可提供的基本信息，以及用户的行为信息，这些我们可以通过埋点获取，而用户的订单情况也是非常的重要的标签。\n\n## 金融类标签体系\n![金融类](/image/用户画像标签体系1-1610100346329.png)\n对于金融行业，最明显的区别是增加了用户的价值和用户风险的信息。这些信息在用户申请贷款时一般都可以提供，还有很多信息需要通过征信获取。\n\n最终，不管是电商还是金融或者其他领域，我们都可以通过数据对用户进行画像，最终建立标签体系，影响我们的业务，最终实现战略目的。\n\n下面我们来具体看一下如何一步步的分析建立整体标签体系。\n\n## 标签的维度与类型\n在我们建立用户标签时，首先要明确基于哪种维度去建立标签。\n\n一般除了基于用户维度（userid）建立用户标签体系外，还有基于设备维度（cookieid）建立相应的标签体系，当用户没有登录设备时，就需要这个维度。当然这两个维度还可以进行关联。\n\n而两者的关联就是需要ID-Mapping算法来解决，这也是一个非常复杂的算法。更多的时候我们还是以用户的唯一标识来建立用户画像。\n\n而标签也分为很多种类型，这里参照常见的分类方式，\n\n从对用户打标签的方式来看，一般分为三种类型：1、基于统计类的标签；2、基于规则类的标签、3、基于挖掘类的标签。下面我们介绍这三种类型标签的区别：\n\n+ 统计类标签：这类标签是最为基础也最为常见的标签类型，例如对于某个用户来说，他的性别、年龄、城市、星座、近7日活跃时长、近7日活跃天数、近7日活跃次数等字段可以从用户注册数据、用户访问、消费类数据中统计得出。该类标签构成了用户画像的基础；\n\n+ 规则类标签：该类标签基于用户行为及确定的规则产生。例如对平台上“消费活跃”用户这一口径的定义为近30天交易次数>=2。在实际开发画像的过程中，由于运营人员对业务更为熟悉、而数据人员对数据的结构、分布、特征更为熟悉，因此规则类标签的规则确定由运营人员和数据人员共同协商确定；\n\n+ 机器学习挖掘类标签：该类标签通过数据挖掘产生，应用在对用户的某些属性或某些行为进行预测判断。例如根据一个用户的行为习惯判断该用户是男性还是女性，根据一个用户的消费习惯判断其对某商品的偏好程度。该类标签需要通过算法挖掘产生。\n\n标签的类型是对标签的一个区分，方便我们了解标签是在数据处理的哪个阶段产生的，也更方便我们管理。\n\n## 标签分级分类\n标签需要进行分级分类的管理，一方面使得标签更加的清晰有条件，另一方面也方便我们对标签进行存储查询，也就是管理标签。\n\n![标签分级分类](/image/用户画像标签体系1-1610100447523.png)\n用户画像体系和标签分类从两个不同角度来梳理标签，用户画像体系偏战略和应用，标签分类偏管理和技术实现侧。\n\n把标签分成不同的层级和类别，一是方便管理数千个标签，让散乱的标签体系化；二是维度并不孤立，标签之间互有关联；三可以为标签建模提供标签子集。\n\n梳理某类别的子分类时，尽可能的遵循MECE原则（相互独立、完全穷尽），尤其是一些有关用户分类的，要能覆盖所有用户，但又不交叉。比如：用户活跃度的划分为核心用户、活跃用户、新用户、老用户、流失用户，用户消费能力分为超强、强、中、弱，这样按照给定的规则每个用户都有分到不同的组里。\n\n## 标签命名\n标签的命名也是为了我们可以对标签进行统一的管理，也更好识别出是什么标签。\n\n![标签命名](/image/用户画像标签体系1-1610100479337.png)\n这是一种非常好的命名方式，解释如下：\n\n标签主题：用于刻画属于那种类型的标签，如用户属性、用户行为、用户消费、风险控制等多种类型，可用A、B、C、D等\n字母表示各标签主题；\n+ 标签类型：标签类型可划为分类型和统计型这两种类型，其中分类型用于刻画用户属于哪种类型，如是男是女、是否是会员、\n是否已流失等标签，统计型标签用于刻画统计用户的某些行为次数，如历史购买金额、优惠券使用次数、近30日登陆次数等\n标签，这类标签都需要对应一个用户相应行为的权重次数；\n+ 开发方式：开发方式可分为统计型开发和算法型开发两大开发方式。其中统计型开发可直接从数据仓库中各主题表建模加工\n而成，算法型开发需要对数据做机器学习的算法处理得到相应的标签；\n+ 是否互斥标签：对应同一级类目下（如一级标签、二级标签），各标签之间的关系是否为互斥，可将标签划分为互斥关系和\n非互斥关系。例如对于男、女标签就是互斥关系，同一个用户不是被打上男性标签就是女性标签，对于高活跃、中活跃、低\n活跃标签也是互斥关系；\n+ 用户维度：用于刻画该标签是打在用户唯一标识（userid）上，还是打在用户使用的设备（cookieid）上。可用U、C等字\n母分别标识userid和cookieid维度。\n\n最终形成得标签示例：\n\n对于用户是男是女这个标签，标签主题是用户属性，标签类型属于分类型，开发方式为统计型，为互斥关系，用户\n维度为userid。这样给男性用户打上标签“A111U001_001”，女性用户打上标签“A111U001_002”，其中\n“A111U”为上面介绍的命名方式，“001”为一级标签的id，后面对于用户属性维度的其他一级标签可用“002”、\n“003”等方式追加命名，“_”后面的“001”和“002”为该一级标签下的标签明细，如果是划分高、中、低活跃\n用户的，对应一级标签下的明细可划分为“001”、“002”、“003”。\n![ddl](/image/用户画像标签体系1-1610100518466.png)\n\n## 标签存储与管理\n### Hive与Druid数仓存储标签计算结果集\n因为数据非常大，所以跑标签出来的结果必须要通过hive和druid数仓引擎来完成。\n\n在数据仓库的建模过程中，主要是事实表和维度表的开发。\n\n事实表依据业务来开发，描述业务的过程，可以理解为我们对原始数据做ETL整理后业务事实。\n\n而维度表就是我们最终形成的用户维度，维度表是实时变化的，逐渐的建立起用户的画像。\n\n比如用户维度标签：\n\n首先我们根据之前讨论的用户指标体系，将用户按照人口，行为，消费等等建立相关中间表，注意表的命名。\n\n![ETL](/image/用户画像标签体系1-1610100559561.png)\n第一张人口属性表：\n\n![人口属性](/image/用户画像标签体系1-1610100569781.png)\n同样的，其他的也按这种方式进行存储，这种属性类的计算很容易筛选出来。\n\n然后，我们将用户的标签查询出来，汇总到用户身上：\n![汇总sql](/image/用户画像标签体系1-1610100589257.png)\n最终用户的标签就形成了\n\n![用户标签](/image/用户画像标签体系1-1610100608905.png)\n当然，对于复杂的规则和算法类标签，就需要在计算中间表时做更复杂的计算，我们需要在Flink里解决这些复杂的计算，未来开发中我们会详细的讨论，这一部分先根据标签体系把相应的表结构都设计出来。\n\n### Mysql存储标签元数据\nMysql对于小数据量的读写速度更快，也更适合我们对标签定义，管理。我们也可以在前端开发标签的管理页面。\n\n![metadata](/image/用户画像标签体系1-1610100632944.png)\n我们在mysql存储的字段如图所示，在页面上提供编辑等功能，在开发标签的过程中，就可以控制标签的使用了。\n\n这样，我们的标签体系已经根据实际的业务情况建立起来了，在明确了标签体系以后，也就明确了我们的业务支撑。\n\n从下一章开始我们将正式开始搭建大数据集群，接入数据，进行标签开发。\n\n\n\n转载自 [用户画像标签体系——从零开始搭建实时用户画像(三)](https://www.cnblogs.com/tree1123/p/12979172.html)","tags":["trident"],"categories":["trident 标签 画像"]},{"title":"标签体系","url":"/2021/01/08/标签体系/","content":"\n## 周期性标签运行\n\n### 获取需要执行的标签\n\nCronJobLauncher。10s扫描一次\n\n```sql\nSELECT i.id,\n       i.label_unique_id,\n       i.label_name,\n       i.label_type,\n       i.demand,\n       i.rule_descriptor,\n       i.rule_hash,\n       i.dsl_config,\n       i.execute_config,\n       i.next_run_time,\n       i.rule_recent_updated,\n       i.expire_type,\n       i.expire_value,\n       i.es_type,\n       t.cron_config AS tree_cron_config,\n       IFNULL(i.cron_config,t.cron_config) AS cron_config,\n       t.tree_type_id AS tree_type,\n       i.tree_id,\n       i.root_label_id,\n       i.parent_label_id,\n       i.depth,\n       i.acc_id,\n       i.emails,\n       i.del_flag,\n       i.create_time,\n       i.update_time,\n       i.label_count,\n       i.one_time_status\nFROM t_trident_label_info i\nLEFT JOIN t_trident_label_tree t ON t.tree_id = i.tree_id\nWHERE i.del_flag = 0\n  AND i.execute_config IS NOT NULL\n  AND i.dsl_config IS NOT NULL\n  AND (i.next_run_time > '1970-01-01 08:00:00'\n       AND i.next_run_time <= NOW())\n  AND i.one_time_status <> 2\n```\n\n桉树id分组\n\n遍历每个分组，如果分组下的标签执行周期 != 树的执行周期，ofSpecialCronJob 立即提交任务（fusion）\n\n否则合并多个标签任务id，ofNormalCronJob 提交任务（merged，waitForBatch=true） \n\n遍历完成后，更新下次执行时间（nextRunTime）\n\n以上任务提交后都先放在redis的```ds:trident:mq:allJob```​队列中\n\n\n\n运行中的任务在 redis的 ```ds:trident:scheduler:running```中\n\n![image-20210106101222963](/image/image-20210106101222963.png)\n\n### 任务分发\n\nJobAcceptor。 10s扫描一次 redis中的```ds:trident:mq:allJob```队列\n\n#### fusion\n\n将fusion作业直接提交到海纳执行，sendJobToTracker 放到```ds:trident:scheduler:running```中\n\n#### merged\n\n将merged且waitForBatch=false的，进行合并。ExecutionPlanner.INSTANCE.merge(ImmutableList.of(jobCtx))，然后提交海纳，sendJobToTracker 放到```ds:trident:scheduler:running```中\n\n```mermaid\ngraph LR\n\t合并任务-->condition{是否大于合并阈值}\n\tcondition--否,简单合并-->将多个sql语句放到一个task里面\n\tcondition--是,深度合并-->对sql逻辑进行合并后放到一个task里面\n```\n\n合并任务相关单元测试可以参考com.datastory.trident.serv.scheduler.ExecutionPlannerTest\n\n\n\n将merged且waitForBatch=true的，提交到```ds:trident:mq:mergeJob```队列\n\n![image-20210106144024660](/image/image-20210106144024660.png)\n\n```json\n{\"labelJobIdMap\":{\"2048\":1133541,\"2049\":1133542,\"2050\":1133543,\"2051\":1133544,\"2052\":1133545,\"2053\":1133546,\"2054\":1133547,\"2055\":1133548,\"2056\":1133549,\"2058\":1133550,\"2059\":1133551,\"2060\":1133552,\"2061\":1133553,\"2062\":1133554,\"2063\":1133555,\"2064\":1133556,\"2065\":1133557,\"2066\":1133558,\"2068\":1133559,\"2069\":1133560,\"2070\":1133561,\"2071\":1133562,\"2072\":1133563,\"2073\":1133564,\"2074\":1133565,\"2075\":1133566,\"2076\":1133567,\"2077\":1133568,\"2078\":1133569,\"2079\":1133570,\"2080\":1133571,\"2082\":1133572,\"2083\":1133573,\"2084\":1133574,\"2094\":1133575,\"2095\":1133576,\"2096\":1133577,\"2097\":1133578,\"2098\":1133579,\"2099\":1133580,\"2100\":1133581,\"2101\":1133582,\"2105\":1133583,\"2106\":1133584,\"2107\":1133585,\"2108\":1133586,\"2110\":1133587,\"2111\":1133588,\"2113\":1133589,\"2114\":1133590,\"2115\":1133591,\"2116\":1133592,\"2117\":1133593,\"2118\":1133594,\"2119\":1133595,\"2120\":1133596,\"2122\":1133597,\"2123\":1133598,\"2124\":1133599,\"2125\":1133600,\"2126\":1133601,\"2127\":1133602,\"2128\":1133603,\"2129\":1133604,\"2130\":1133605,\"2131\":1133606,\"2132\":1133607,\"2135\":1133608,\"2136\":1133609,\"2137\":1133610,\"2138\":1133611,\"2139\":1133612,\"2141\":1133613,\"2142\":1133614,\"2143\":1133615,\"2144\":1133616,\"2145\":1133617,\"2146\":1133618,\"2147\":1133619,\"2148\":1133620,\"2149\":1133621,\"2150\":1133622,\"2151\":1133623,\"2153\":1133624,\"2154\":1133625,\"2155\":1133626,\"2156\":1133627,\"2157\":1133628,\"2158\":1133629,\"2159\":1133630,\"2160\":1133631,\"2161\":1133632,\"2163\":1133633,\"2164\":1133634,\"2165\":1133635,\"2166\":1133636,\"2167\":1133637,\"2168\":1133638,\"2169\":1133639,\"2170\":1133640,\"2171\":1133641,\"2172\":1133642,\"2173\":1133643,\"2174\":1133644,\"2175\":1133645,\"2177\":1133646,\"2178\":1133647,\"2179\":1133648,\"2189\":1133649,\"2190\":1133650,\"2191\":1133651,\"2192\":1133652,\"2193\":1133653,\"2194\":1133654,\"2195\":1133655,\"2196\":1133656,\"2200\":1133657,\"2201\":1133658,\"2202\":1133659,\"2203\":1133660,\"2205\":1133661,\"2206\":1133662,\"2208\":1133663,\"2209\":1133664,\"2210\":1133665,\"2211\":1133666,\"2212\":1133667,\"2214\":1133668,\"2215\":1133669,\"2216\":1133670,\"2217\":1133671,\"2218\":1133672,\"2219\":1133673,\"2220\":1133674,\"2221\":1133675,\"2222\":1133676,\"2223\":1133677,\"2224\":1133678,\"2227\":1133679,\"2228\":1133680,\"2229\":1133681,\"2230\":1133682,\"2231\":1133683,\"2233\":1133684,\"2234\":1133685,\"2235\":1133686,\"2236\":1133687,\"2237\":1133688,\"2238\":1133689,\"2239\":1133690,\"2240\":1133691,\"2241\":1133692,\"2242\":1133693,\"2243\":1133694,\"2245\":1133695,\"2246\":1133696,\"2247\":1133697,\"2248\":1133698,\"2249\":1133699,\"2250\":1133700,\"2251\":1133701,\"2252\":1133702,\"2253\":1133703,\"2255\":1133704,\"2256\":1133705,\"2257\":1133706,\"2258\":1133707,\"2259\":1133708,\"2260\":1133709,\"2261\":1133710,\"2262\":1133711,\"2263\":1133712,\"2264\":1133713,\"2265\":1133714,\"2266\":1133715,\"2267\":1133716,\"2269\":1133717,\"2270\":1133718,\"2271\":1133719,\"2273\":1133720,\"2278\":1133721,\"2280\":1133722,\"2298\":1133723,\"2299\":1133724,\"2300\":1133725,\"2301\":1133726,\"2302\":1133727,\"2303\":1133728,\"2304\":1133729,\"2305\":1133730,\"2309\":1133731,\"2310\":1133732,\"2311\":1133733,\"2312\":1133734,\"2314\":1133735,\"2315\":1133736,\"2317\":1133737,\"2318\":1133738,\"2319\":1133739,\"2320\":1133740,\"2321\":1133741,\"2322\":1133742,\"2323\":1133743,\"2324\":1133744,\"2326\":1133745,\"2327\":1133746,\"2328\":1133747,\"2329\":1133748,\"2330\":1133749,\"2331\":1133750,\"2332\":1133751,\"2333\":1133752,\"2334\":1133753,\"2335\":1133754,\"2336\":1133755,\"2339\":1133756,\"2340\":1133757,\"2341\":1133758,\"2342\":1133759,\"2343\":1133760,\"2345\":1133761,\"2346\":1133762,\"2347\":1133763,\"2348\":1133764,\"2349\":1133765,\"2350\":1133766,\"2351\":1133767,\"2352\":1133768,\"2353\":1133769,\"2354\":1133770,\"2355\":1133771,\"2357\":1133772,\"2358\":1133773,\"2359\":1133774,\"2360\":1133775,\"2361\":1133776,\"2362\":1133777,\"2363\":1133778,\"2364\":1133779,\"2365\":1133780,\"2367\":1133781,\"2368\":1133782,\"2369\":1133783,\"2370\":1133784,\"2371\":1133785,\"2372\":1133786,\"2373\":1133787,\"2374\":1133788,\"2375\":1133789,\"2376\":1133790,\"2377\":1133791,\"2378\":1133792,\"2379\":1133793,\"2381\":1133794,\"2382\":1133795,\"2383\":1133796,\"2405\":1133797,\"2406\":1133798,\"2407\":1133799,\"2408\":1133800,\"2409\":1133801,\"2410\":1133802,\"2411\":1133803,\"2412\":1133804,\"2416\":1133805,\"2417\":1133806,\"2418\":1133807,\"2419\":1133808,\"2421\":1133809,\"2422\":1133810,\"2424\":1133811,\"2425\":1133812,\"2426\":1133813,\"2427\":1133814,\"2428\":1133815,\"2429\":1133816,\"2430\":1133817,\"2431\":1133818,\"2433\":1133819,\"2434\":1133820,\"2435\":1133821,\"2436\":1133822,\"2437\":1133823,\"2438\":1133824,\"2439\":1133825,\"2440\":1133826,\"2441\":1133827,\"2442\":1133828,\"2443\":1133829,\"2446\":1133830,\"2447\":1133831,\"2448\":1133832,\"2449\":1133833,\"2450\":1133834,\"2452\":1133835,\"2453\":1133836,\"2454\":1133837,\"2455\":1133838,\"2456\":1133839,\"2457\":1133840,\"2458\":1133841,\"2459\":1133842,\"2460\":1133843,\"2461\":1133844,\"2462\":1133845,\"2464\":1133846,\"2465\":1133847,\"2466\":1133848,\"2467\":1133849,\"2468\":1133850,\"2469\":1133851,\"2470\":1133852,\"2471\":1133853,\"2472\":1133854,\"2474\":1133855,\"2475\":1133856,\"2476\":1133857,\"2477\":1133858,\"2478\":1133859,\"2479\":1133860,\"2480\":1133861,\"2481\":1133862,\"2482\":1133863,\"2483\":1133864,\"2484\":1133865,\"2485\":1133866,\"2486\":1133867,\"2488\":1133868,\"2489\":1133869,\"2490\":1133870,\"2509\":1133871,\"2510\":1133872,\"2515\":1133873,\"2528\":1133874,\"2529\":1133875,\"1622\":1133876,\"1623\":1133877,\"1624\":1133878,\"1625\":1133879,\"1626\":1133880,\"1627\":1133881,\"1628\":1133882,\"1629\":1133883,\"1633\":1133884,\"1634\":1133885,\"1635\":1133886,\"1636\":1133887,\"1638\":1133888,\"1639\":1133889,\"1641\":1133890,\"1642\":1133891,\"1643\":1133892,\"1644\":1133893,\"1645\":1133894,\"1646\":1133895,\"1647\":1133896,\"1648\":1133897,\"1650\":1133898,\"1651\":1133899,\"1652\":1133900,\"1653\":1133901,\"1654\":1133902,\"1655\":1133903,\"1656\":1133904,\"1657\":1133905,\"1658\":1133906,\"1659\":1133907,\"1660\":1133908,\"1663\":1133909,\"1664\":1133910,\"1665\":1133911,\"1666\":1133912,\"1667\":1133913,\"1669\":1133914,\"1670\":1133915,\"1683\":1133916,\"1684\":1133917,\"1685\":1133918,\"1686\":1133919,\"1687\":1133920,\"1688\":1133921,\"1689\":1133922,\"1690\":1133923,\"1691\":1133924,\"1693\":1133925,\"1694\":1133926,\"1695\":1133927,\"1696\":1133928,\"1698\":1133929,\"1699\":1133930,\"1700\":1133931,\"1701\":1133932,\"1702\":1133933,\"1704\":1133934,\"1705\":1133935,\"1706\":1133936,\"1707\":1133937,\"1708\":1133938,\"1709\":1133939,\"1710\":1133940,\"1711\":1133941,\"1712\":1133942,\"1713\":1133943,\"1714\":1133944,\"1715\":1133945,\"1716\":1133946,\"1718\":1133947,\"1719\":1133948,\"1720\":1133949,\"1783\":1133950,\"1784\":1133951,\"1785\":1133952,\"1786\":1133953,\"1787\":1133954,\"1788\":1133955,\"1789\":1133956,\"1790\":1133957,\"1794\":1133958,\"1795\":1133959,\"1796\":1133960,\"1797\":1133961,\"1799\":1133962,\"1800\":1133963,\"1805\":1133964,\"1806\":1133965,\"1807\":1133966,\"1808\":1133967,\"1809\":1133968,\"1811\":1133969,\"1812\":1133970,\"1813\":1133971,\"1814\":1133972,\"1815\":1133973,\"1816\":1133974,\"1817\":1133975,\"1818\":1133976,\"1819\":1133977,\"1820\":1133978,\"1821\":1133979,\"1824\":1133980,\"1825\":1133981,\"1826\":1133982,\"1827\":1133983,\"1828\":1133984,\"1830\":1133985,\"1831\":1133986,\"1832\":1133987,\"1833\":1133988,\"1834\":1133989,\"1835\":1133990,\"1836\":1133991,\"1837\":1133992,\"1838\":1133993,\"1839\":1133994,\"1840\":1133995,\"1842\":1133996,\"1843\":1133997,\"1844\":1133998,\"1845\":1133999,\"1846\":1134000,\"1847\":1134001,\"1848\":1134002,\"1849\":1134003,\"1850\":1134004,\"1852\":1134005,\"1853\":1134006,\"1854\":1134007,\"1855\":1134008,\"1856\":1134009,\"1857\":1134010,\"1858\":1134011,\"1859\":1134012,\"1860\":1134013,\"1861\":1134014,\"1862\":1134015,\"1863\":1134016,\"1864\":1134017,\"1866\":1134018,\"1867\":1134019,\"1868\":1134020,\"1884\":1134021,\"1885\":1134022,\"1886\":1134023,\"1887\":1134024,\"1888\":1134025,\"1889\":1134026,\"1890\":1134027,\"1891\":1134028,\"1895\":1134029,\"1896\":1134030,\"1897\":1134031,\"1898\":1134032,\"1900\":1134033,\"1901\":1134034,\"1903\":1134035,\"1904\":1134036,\"1905\":1134037,\"1906\":1134038,\"1907\":1134039,\"1908\":1134040,\"1909\":1134041,\"1910\":1134042,\"1912\":1134043,\"1913\":1134044,\"1914\":1134045,\"1915\":1134046,\"1916\":1134047,\"1917\":1134048,\"1918\":1134049,\"1919\":1134050,\"1920\":1134051,\"1921\":1134052,\"1922\":1134053,\"1925\":1134054,\"1926\":1134055,\"1927\":1134056,\"1928\":1134057,\"1929\":1134058,\"1931\":1134059,\"1932\":1134060,\"1933\":1134061,\"1934\":1134062,\"1935\":1134063,\"1936\":1134064,\"1937\":1134065,\"1938\":1134066,\"1939\":1134067,\"1940\":1134068,\"1941\":1134069,\"1943\":1134070,\"1944\":1134071,\"1945\":1134072,\"1946\":1134073,\"1947\":1134074,\"1948\":1134075,\"1949\":1134076,\"1950\":1134077,\"1951\":1134078,\"1953\":1134079,\"1954\":1134080,\"1955\":1134081,\"1956\":1134082,\"1957\":1134083,\"1958\":1134084,\"1959\":1134085,\"1960\":1134086,\"1961\":1134087,\"1962\":1134088,\"1963\":1134089,\"1964\":1134090,\"1965\":1134091,\"1967\":1134092,\"1968\":1134093,\"1969\":1134094,\"1999\":1134095,\"2000\":1134096,\"2001\":1134097,\"2002\":1134098,\"2003\":1134099,\"2004\":1134100,\"2005\":1134101,\"2006\":1134102,\"2010\":1134103,\"2011\":1134104,\"2012\":1134105,\"2013\":1134106,\"2015\":1134107,\"2016\":1134108,\"2018\":1134109,\"2019\":1134110,\"2020\":1134111,\"2021\":1134112,\"2022\":1134113,\"2023\":1134114,\"2024\":1134115,\"2025\":1134116,\"2027\":1134117,\"2028\":1134118,\"2029\":1134119,\"2030\":1134120,\"2031\":1134121,\"2032\":1134122,\"2033\":1134123,\"2034\":1134124,\"2035\":1134125,\"2036\":1134126,\"2037\":1134127,\"2040\":1134128,\"2041\":1134129,\"2042\":1134130,\"2043\":1134131,\"2044\":1134132,\"2046\":1134133,\"2047\":1134134},\"waitForBatch\":true,\"jobType\":\"MERGED\",\"treeId\":256,\"treeTypeId\":497}\n```\n\n\n\n### 合并的任务\n\nBatchJobAcceptor。2小时扫描一次\n\n处理过程同merged 且watiForBatch=false，只是多了个等待时间，会收到多个jobCtx，ExecutionPlanner.INSTANCE.merge(jobCtxList)\n\n\n\n<font color=\"#FF000\">**难点在于合并任务的逻辑处理。@see com.datastory.trident.serv.scheduler.ExecutionPlanner#merge**</font>\n\n\n\n## 修改标签规则\n\n```mermaid\ngraph TD;\n\tsubgraph all[全部]\n\tstart[开始]-->edit[修改标签]\n\tedit--执行标签任务-->redis[提交到redis的allJob队列]\n\tredis--JobAcceptor#parseMessage-->runJob[执行标签 调用海纳]\t\n\trunJob-->ostart\n\tend\n\tsubgraph ocean[海纳任务]\n\tostart[海纳task]-->oend[海纳任务执行完成]\n\tostart-->jstart\n\tend\n\tsubgraph JobTracker\n\tjstart[从redis的scheduler:running获取运行中的任务]-->isJobEnd{任务是否到达终态}\n\tisJobEnd--是-->updateLabelCoverage[更新标签覆盖数]-->processRuleUpdatedLabel{判断规则是否改过}\n\tupdateLabelCoverage-->processOneTimeLabelStatus[一次性标签需要修改oneTimeStatus状态位为已执行]-->removeFromRedisSet[从redis的running中删除]-->oend\n\tisJobEnd--否-->jstart\n\tprocessRuleUpdatedLabel--是-->cleanStart\n\tend\n\tsubgraph ofCleanOldRuleJob[清理修改过规则后的过期标签]\n\tcleanStart-->cleanEnd\n\tend\n```\n### 任务终态定义\n```java\n\nthis.equals(SUCCESS) || this.equals(TIMEOUT) || this.equals(KILLED) || this.equals(FAILED) || this.equals(SYS_KILLED) || this.equals(SYS_FAILED)\n```\n\n","tags":["trident"],"categories":["trident"]},{"title":"Git","url":"/2021/01/07/Git/","content":"# Git\n\n## 合并分支、打tag\n\n参考 [https://wiki.datastory.com.cn/pages/viewpage.action?pageId=38618481#id-%E5%B7%A5%E5%9C%BA%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91README-4.3%E5%8F%91%E5%B8%83&%E6%89%93tag](https://wiki.datastory.com.cn/pages/viewpage.action?pageId=38618481#id-工场后端开发README-4.3发布&打tag)\n\n### 合并分支操作：（以合并dev到master为例子）\n\na. 切换到master分支 git checkout master\n\nb. 合并代码 git merge dev\n\nc. 推到远程 git push\n\n\n### 发布前\n\n\ndev提交pr到master --> idea 下载 gitlab project插件，然后配置下gitlab的服务器 \n\n![gitlab](/image/gitlab-project.png)\n\nreview 然后合并到master\n\n修改版本号 mvn versions:set -DnewVersion=1.4.2.0-SNAPSHOT -DgenerateBackupPoms=false 并提交\n\n发布系统打tag\n\n### 完成后重新rebase\n","tags":["git"],"categories":["git"]},{"title":"hello world","url":"/2018/07/17/hello-world/","content":"\nWelcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/one-command-deployment.html)\n\n### 流程图\n```flow\nst=>start: Start|past:>http://www.google.com[blank]\ne=>end: End:>http://www.google.com\nop1=>operation: My Operation|past\nop2=>operation: Stuff|current\nsub1=>subroutine: My Subroutine|invalid\ncond=>condition: Yes\nor No?|approved:>http://www.google.com\nc2=>condition: Good idea|rejected\nio=>inputoutput: catch something...|request\n\nst->op1(right)->cond\ncond(yes, right)->c2\ncond(no)->sub1(left)->op1\nc2(yes)->io->e\nc2(no)->op2->e\n```\n\n\n### class disagram\n```mermaid\nclassDiagram\n    Class01 <|-- AveryLongClass : Cool\n    Class03 *-- Class04\n    Class05 o-- Class06\n    Class07 .. Class08\n    Class09 --> C2 : Where am i?\n    Class09 --* C3\n    Class09 --|> Class07\n    Class07 : equals()\n    Class07 : Object[] elementData\n    Class01 : size()\n    Class01 : int chimp\n    Class01 : int gorilla\n    Class08 <--> C2: Cool label\n```\n\n### sequence\n```mermaid\nsequenceDiagram\n    participant Alice\n    participant Bob\n    Alice->>John: Hello John, how are you?\n    loop Healthcheck\n        John->>John: Fight against hypochondria\n    end\n    Note right of John: Rational thoughts <br/>prevail...\n    John-->>Alice: Great!\n    John->>Bob: How about you?\n    Bob-->>John: Jolly good!\n```\n### gantt\n\n```mermaid\ngantt\n    dateFormat  YYYY-MM-DD\n    title Adding GANTT diagram to mermaid\n    \n    section A section\n    Completed task            :done,    des1, 2014-01-06,2014-01-08\n    Active task               :active,  des2, 2014-01-09, 3d\n    Future task               :         des3, after des2, 5d\n    Future task2               :         des4, after des3, 5d\n```\n\n### mermaid diagrams\n```mermaid\ngraph TD;\n    A[test]\n    B[hello]\n    D-->G\n    A-->B\n    A-->C\n    B-->D\n    C-->D\n\tsubgraph test\n\tE-->G\n\tend\n```\n### graph TD\n\n```mermaid\ngraph TD;\n\trunJob-->ostart\n\tostart-->jstart\n\tprocessRuleUpdatedLabel--是-->cleanStart\n\tsubgraph all\n\tstart[开始]-->edit[修改标签]\n\tedit--执行标签任务-->redis[提交到redis的allJob队列]\n\tredis--JobAcceptor#parseMessage-->runJob[执行标签 调用海纳]\n\tend\n\n\tsubgraph ocean[海纳任务]\n\tostart[海纳task]-->oend[海纳任务执行完成]\n\tend\n\n\tsubgraph JobTracker\n\tjstart[从redis的scheduler:running获取运行中的任务]-->isJobEnd{任务是否到达终态}\n\tisJobEnd--是-->updateLabelCoverage[更新标签覆盖数]-->processRuleUpdatedLabel{判断规则是否改过}\n\tupdateLabelCoverage-->processOneTimeLabelStatus[一次性标签需要修改oneTimeStatus状态位为已执行]-->removeFromRedisSet[从redis的running中删除]-->oend\n\tisJobEnd--否-->jstart\n\tend\n\n\tsubgraph ofCleanOldRuleJob[清理修改过规则后的过期标签]\n\tcleanStart-->cleanEnd\n\tend\n```","tags":["hexo demo"],"categories":["测试"]}]