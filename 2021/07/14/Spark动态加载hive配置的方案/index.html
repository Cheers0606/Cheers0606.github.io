<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="google-site-verification" content="xBT4GhYoi5qRD5tr338pgPM5OWHHIDR6mNg1a3euekI" />
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="希望能坚持下去">
    <meta name="keyword"  content="enoch">
    <link rel="shortcut icon" href="/img/favicon.ico">

    <title>
        
        Spark动态加载hive配置的方案 - Enoch的博客 | Enoch&#39;s Blog
        
    </title>

    <!-- Custom CSS -->
    
<link rel="stylesheet" href="/css/aircloud.css">

    
<link rel="stylesheet" href="/css/gitment.css">

    <!--<link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css">-->
    <link href="//at.alicdn.com/t/font_620856_pl6z7sid89qkt9.css" rel="stylesheet" type="text/css">
    <!-- ga & ba script hoook -->
    <script></script>
<meta name="generator" content="Hexo 5.4.0"></head>

<body>

<div class="site-nav-toggle" id="site-nav-toggle">
    <button>
        <span class="btn-bar"></span>
        <span class="btn-bar"></span>
        <span class="btn-bar"></span>
    </button>
</div>

<div class="index-about">
    <i> We are all in the gutter, but some of us are looking at the stars. </i>
</div>

<div class="index-container">
    
    <div class="index-left">
        
<div class="nav" id="nav">
    <div class="avatar-name">
        <div class="avatar ">
            <img src="/img/favicon.ico" />
        </div>
        <div class="name">
            <i>Enoch</i>
        </div>
    </div>
    <div class="contents" id="nav-content">
        <ul>
            <li >
                <a href="/">
                    <i class="iconfont icon-shouye1"></i>
                    <span>主页</span>
                </a>
            </li>
            <li >
                <a href="/tags">
                    <i class="iconfont icon-biaoqian1"></i>
                    <span>标签</span>
                </a>
            </li>
            <li >
                <a href="/archive">
                    <i class="iconfont icon-guidang2"></i>
                    <span>存档</span>
                </a>
            </li>
            <li >
                <a href="/about/">
                    <i class="iconfont icon-guanyu2"></i>
                    <span>关于</span>
                </a>
            </li>
            
            <li>
                <a id="search">
                    <i class="iconfont icon-sousuo1"></i>
                    <span>搜索</span>
                </a>
            </li>
            
        </ul>
    </div>
    
        <div id="toc" class="toc-article">
    
</div>
    
</div>


<div class="search-field" id="search-field">
    <div class="search-container">
        <div class="search-input">
            <span id="esc-search"> <i class="icon-fanhui iconfont"></i></span>
            <input id="search-input"/>
            <span id="begin-search">搜索</span>
        </div>
        <div class="search-result-container" id="search-result-container">

        </div>
    </div>
</div>

        <div class="index-about-mobile">
            <i> We are all in the gutter, but some of us are looking at the stars. </i>
        </div>
    </div>
    
    <div class="index-middle">
        <!-- Main Content -->
        


<div class="post-container">
    <div class="post-title">
        Spark动态加载hive配置的方案
    </div>

    <div class="post-meta">
        <span class="attr">发布于：<span>2021-07-14 15:27:15</span></span>
        
        <span class="attr">标签：/
        
        <a class="tag" href="/tags/#spark" title="spark">spark</a>
        <span>/</span>
        
        
        </span>
        <span class="attr">访问：<span id="busuanzi_value_page_pv"></span>
</span>
</span>
    </div>
    <div class="post-content ">
        <blockquote>
<p>转载自 <a target="_blank" rel="noopener" href="https://leibnizhu.github.io/2020/05/06/%E5%8A%A8%E6%80%81%E5%8A%A0%E8%BD%BDhive%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E7%9A%84%E6%96%B9%E6%A1%88/">莱哥博客</a></p>
</blockquote>
<p>一般来说，Spark写Hive，把 <strong>xxx-site.xml</strong>系列配置文件打进jar包里，或spark-submit指定下file之类，new个HiveContext就完事了。<br>要写外部集群，也不外乎是换对应的<strong>xxx-site.xml</strong>，改改<strong>thrift</strong>服务地址啥的，不费劲。<br>好了，本文结束。</p>
<hr>
<p>不对，擅长断更的我不会为此特意写篇博客。</p>
<p>现在的场景是，每次Spark任务启动的时候才能拿到外部Hive集群的配置信息（别问我为什么，问就是中台的需求，很多集群，java应用启动后才能去读到任务配置，反射组装RDD并执行，Hive配置？lazy的，到写入的时候才会去拿）。</p>
<p>这个过程踩了不少坑，试了几种方案，直接说结论吧。</p>
<ul>
<li>SparkContext创建的时候会创建一个Configuration对象（注意 loadDefaults=true)，写入Hive会用到它；而这个Configuration对象里面已经放了常规的那些***-site.xml系列配置文件作为 defaultResources，这时写入Hive相当于按fat-jar里面的配置来了；</li>
<li>围观Configuration代码，reload配置之后会将defaultResources逐个读出，而defaultResources是个有序的List，那么显然可以用Configuration#addDefaultResource()把外部集群的相关配置xml设置为默认资源，这样拿配置的时候就会拿到外部集群的配置啦！！！</li>
<li>为了方便配置的读取，直接放在hdfs吧，这样直接Configuration.addDefaultResource(“hdfs:///path/to/hive-site.xml”)不就可以了吗？诶怎么不行，再围观Configuration代码，可以看到加载默认资源最终用的是Configuration#getResource()方法，这个方法体就一句话：return classLoader.getResource(name);，也就是说，它不会去解析hdfs协议，而是直接从classpath里面去读取。所以不能直接从hdfs读取；</li>
<li>最后的方案是把配置文件放在hdfs，写入Hive前，把它下载到当前classpath的其中某个目录下（比如classpath包含. 则下载到System.getProperty(“user.dir”)下），然后Configuration.addDefaultResource(“hive-site.xml”)，因为Configuration是用ClassLoader进行加载的，所以注意路径没有/。</li>
<li>这就完事了？并不，跑起来会发现还是查询jar包里的hive metastore地址，所以还要解析hive-site.xml，读取出hive.metastore.uris值并放入环境变量中。</li>
<li>这就完事了？并不，考虑到后续还会有其他写入操作，以及SparkContext.stop()操作，这些操作都会用到Configuration读取配置，然而现在以及有了外部集群的默认资源了，需要删掉，然而Configuration并没有提供删除默认资源的方法，所以这里要手动反射删除之。</li>
</ul>
<hr>
<p>最终代码（简化版）：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Slf4j</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">WriteExtraHive</span></span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String HIVE_METASTORE_URIS_KEY = <span class="string">&quot;hive.metastore.uris&quot;</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String BASE_HDFS_PATH = <span class="string">&quot;/path/to/&quot;</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">boolean</span> useSparkSql; <span class="comment">//实际的实现是支持走jdbc和走SparkSql，根据是否有hive的配置文件</span></span><br><span class="line">    <span class="keyword">private</span> Set&lt;String&gt; extraDefaultResource = <span class="keyword">new</span> HashSet&lt;&gt;();</span><br><span class="line">    <span class="keyword">private</span> String hosts; <span class="comment">//集群节点，这里只用于区分hdfs的配置路径</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">write</span><span class="params">()</span></span>&#123;</span><br><span class="line">        init(); <span class="comment">//加载配置</span></span><br><span class="line">        write(); <span class="comment">//真正写hive</span></span><br><span class="line">        end(); <span class="comment">//移除额外添加的默认资源</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">init</span><span class="params">()</span></span>&#123;</span><br><span class="line">        URL.setURLStreamHandlerFactory(<span class="keyword">new</span> FsUrlStreamHandlerFactory());</span><br><span class="line">        String hiveSiteXmlPath = calHadoopXmlPath(hosts, <span class="string">&quot;hive-site&quot;</span>, <span class="keyword">false</span>);</span><br><span class="line">        useSparkSql = hiveSiteXmlPath != <span class="keyword">null</span>;</span><br><span class="line">        log.info(<span class="string">&quot;hive-site.xml文件(&#123;&#125;)存在:&#123;&#125;&quot;</span>, hiveSiteXmlPath, useSparkSql);</span><br><span class="line">        <span class="keyword">if</span> (useSparkSql) &#123;</span><br><span class="line">            String hiveMetaStoreUris = parseMetaStoreUri(hiveSiteXmlPath);</span><br><span class="line">            <span class="keyword">if</span> (StringUtils.isNotEmpty(hiveMetaStoreUris)) &#123;</span><br><span class="line">                log.info(<span class="string">&quot;从hive-site.xml文件读取到&#123;&#125;=&#123;&#125;,并设置到环境变量&quot;</span>, HIVE_METASTORE_URIS_KEY, hiveMetaStoreUris);</span><br><span class="line">                System.setProperty(HIVE_METASTORE_URIS_KEY, hiveMetaStoreUris);</span><br><span class="line">                calHadoopXmlPath(hosts, <span class="string">&quot;hive-site&quot;</span>, <span class="keyword">true</span>);</span><br><span class="line">                calHadoopXmlPath(hosts, <span class="string">&quot;hdfs-site&quot;</span>, <span class="keyword">true</span>);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                useSparkSql = <span class="keyword">false</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">write</span><span class="params">()</span></span>&#123;</span><br><span class="line">        HiveContext hiveContext = <span class="keyword">new</span> HiveContext(sc); <span class="comment">//别问我从哪来的SparkContext,示例代码，随意看看</span></span><br><span class="line">        DataFrame docDataFrame = hiveContext.createDataFrame(rowRdd, sparkSchema); <span class="comment">//rdd和Schema也是，别问</span></span><br><span class="line">        docDataFrame.write()</span><br><span class="line">                .mode(SaveMode.Overwrite)</span><br><span class="line">                .saveAsTable(<span class="string">&quot;xxx.yyy&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">end</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">synchronized</span> (Configuration.class) &#123;</span><br><span class="line">            Configuration tempalte = <span class="keyword">new</span> Configuration(<span class="keyword">false</span>);</span><br><span class="line">            CopyOnWriteArrayList&lt;String&gt; defaultResources = TestUtil.getPrivateField(conf, <span class="string">&quot;defaultResources&quot;</span>); <span class="comment">//getPrivateField方法如其名，递归父类拿到字段并设可见再读</span></span><br><span class="line">            <span class="keyword">if</span> (defaultResources == <span class="keyword">null</span>) &#123;</span><br><span class="line">                <span class="keyword">return</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">for</span> (String resource : extraDefaultResource) &#123;</span><br><span class="line">                defaultResources.remove(resource);</span><br><span class="line">            &#125;</span><br><span class="line">            WeakHashMap&lt;Configuration, Object&gt; REGISTRY = TestUtil.getPrivateField(conf, <span class="string">&quot;REGISTRY&quot;</span>);</span><br><span class="line">            <span class="keyword">if</span> (REGISTRY == <span class="keyword">null</span>) &#123;</span><br><span class="line">                <span class="keyword">return</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">for</span> (Configuration curConf : REGISTRY.keySet()) &#123;</span><br><span class="line">                Boolean loadDefaults = TestUtil.getPrivateField(curConf, <span class="string">&quot;loadDefaults&quot;</span>);</span><br><span class="line">                <span class="keyword">if</span> (loadDefaults != <span class="keyword">null</span> &amp;&amp; loadDefaults) &#123;</span><br><span class="line">                    curConf.reloadConfiguration();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">private</span> String <span class="title">calHadoopXmlPath</span><span class="params">(String hosts, String fileName, <span class="keyword">boolean</span> addToDefaultRs)</span> </span>&#123;</span><br><span class="line">        String hdfsPath = String.format(<span class="string">&quot;hdfs://%shive/%s-%s.xml&quot;</span>, BASE_HDFS_PATH, hosts, fileName);</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            FileSystem fs = FileSystem.get(<span class="keyword">new</span> Configuration());</span><br><span class="line">            <span class="keyword">if</span> (HdfsUtil.isFileExist(hdfsPath, fs)) &#123;</span><br><span class="line">                <span class="keyword">if</span> (addToDefaultRs) &#123;</span><br><span class="line">                    ClassLoader classLoader = Thread.currentThread().getContextClassLoader();</span><br><span class="line">                    URL cpResource = classLoader.getResource(<span class="string">&quot;&quot;</span>);</span><br><span class="line">                    String cpDir = cpResource != <span class="keyword">null</span> ? cpResource.getPath() : (System.getProperty(<span class="string">&quot;user.dir&quot;</span>) + File.separator);</span><br><span class="line">                    String downloadFileName = String.format(<span class="string">&quot;%s-%s_%s.xml&quot;</span>, hosts, fileName, System.currentTimeMillis()); <span class="comment">//实际下载本地的名字</span></span><br><span class="line">                    String fullDownloadFilePath = cpDir + downloadFileName;</span><br><span class="line">                    log.info(<span class="string">&quot;增加Hadoop配置文件:&#123;&#125;到Configuration默认资源,下载到本地:&#123;&#125;&quot;</span>, hdfsPath, fullDownloadFilePath);</span><br><span class="line">                    <span class="keyword">try</span> (OutputStream os = <span class="keyword">new</span> BufferedOutputStream(<span class="keyword">new</span> FileOutputStream(fullDownloadFilePath))) &#123;</span><br><span class="line">                        HdfsUtil.copyFileAsStream(hdfsPath, os, fs);</span><br><span class="line">                        Configuration.addDefaultResource(downloadFileName); <span class="comment">//加入默认资源</span></span><br><span class="line">                        extraDefaultResource.add(downloadFileName); <span class="comment">//记录加过哪些默认资源，后面要移除</span></span><br><span class="line">                    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                        log().error(e.getMessage(), e);</span><br><span class="line">                    &#125;</span><br><span class="line">                    log.info(<span class="string">&quot;增加Hadoop配置文件:&#123;&#125;后读取classLoader.getResource(&#123;&#125;)=&#123;&#125;&quot;</span>, fileName, downloadFileName, classLoader.getResource(downloadFileName));</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">return</span> hdfsPath;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                log.info(<span class="string">&quot;不存在文件:&#123;&#125;&quot;</span>, fileName);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            log.error(<span class="string">&quot;get FileSystem fail!&quot;</span>, e);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">private</span> String <span class="title">parseMetaStoreUri</span><span class="params">(String hiveSiteXmlPath)</span> </span>&#123;</span><br><span class="line">        Configuration conf = <span class="keyword">new</span> Configuration(<span class="keyword">false</span>);</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            conf.addResource(<span class="keyword">new</span> URL(hiveSiteXmlPath));</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> conf.get(HIVE_METASTORE_URIS_KEY);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
        
        <br />
        <div id="comment-container">
        </div>
        <div id="disqus_thread"></div>

        <div id="lv-container">
        </div>

    </div>
</div>

    </div>
</div>


<footer class="footer">
    <ul class="list-inline text-center">
        
        

        

        

        
        <li>
            <a target="_blank"  href="https://github.com/Cheers0606">
                            <span class="fa-stack fa-lg">
                                <i class="iconfont icon-github"></i>
                            </span>
            </a>
        </li>
        

        

    </ul>
    
    <p>
        <span>/</span>
        
        <span><a target="_blank" rel="noopener" href="https://www.baidu.com">百度一下</a></span>
        <span>/</span>
        
        <span><a href="#">It helps SEO</a></span>
        <span>/</span>
        
    </p>
    
    <p>
        <span id="busuanzi_container_site_pv">
            <span id="busuanzi_value_site_pv"></span>PV
        </span>
        <span id="busuanzi_container_site_uv">
            <span id="busuanzi_value_site_uv"></span>UV
        </span>
        Created By <a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a>  Theme <a target="_blank" rel="noopener" href="https://github.com/aircloud/hexo-theme-aircloud">AirCloud</a></p>
</footer>




</body>

<script>
    // We expose some of the variables needed by the front end
    window.hexo_search_path = "search.json"
    window.hexo_root = "/"
    window.isPost = true
</script>
<script src="https://cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script>

<script src="/js/index.js"></script>

<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>


    <script>
        /**
         *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
         *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
        */
        if( '' || '')
        var disqus_config = function () {
            this.page.url = '';  // Replace PAGE_URL with your page's canonical URL variable
            this.page.identifier = ''; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
        };

        (function() { // DON'T EDIT BELOW THIS LINE
            var d = document, s = d.createElement('script');
            s.src = 'https://enochblog.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        })();
    </script>



</html>
